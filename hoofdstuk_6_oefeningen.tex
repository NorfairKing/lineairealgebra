\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\chapter{Oefeningen Hoofdstuk 6}

\section{Oefeningen 6.8}


\subsection{Oefening 1}
\subsubsection*{Te Bewijzen}
\[
(\mathbb{R},\mathbb{R}^{2\times 2},+,\langle \cdot,\cdot \rangle ) \text{ is een euclidische ruimte}
\]
Waarbij het inproduct als volgt gedefinieerd is.
\[
\langle A,B \rangle = Tr(A^T\cdot B)
\]

\subsubsection*{Bewijs}
Dit is een heel langdradig bewijs, maar het is hier toch eens volledig uitgeschreven bij wijze van voorbeeld.
\begin{proof}
$(\mathbb{R},\mathbb{R}^{2\times 2},+,Tr)$ is een eindig dimensionale vectorruimte.
We moeten dus enkel de eigenschappen van $\langle A,B \rangle = Tr(A^T,B)$ als inproduct nagaan.\\
Kies willekeurige $V_1,V_2,V, W \in \mathbb{R}^{2\times 2}$ en $\lambda_1,\lambda_2 \in \mathbb{R}^{2\times 2}$.

\begin{itemize}
\item Lineariteit in de eerste component.\\
\[
\langle \lambda_1V_1 + \lambda_2V_2,W \rangle
= Tr((\lambda_1V_1 + \lambda_2V_2)^T\cdot W)
= Tr((\lambda_1V_1^T + \lambda_2V_2^T)\cdot W)
\]
Bovenstaande gelijkheden gelden omwille van de gegeven definitie en de lineariteit van het transponeren van een matrix \footnote{Zie Eigenschap 1.16 p 28.}.
Volgende gelijkheid geldt omdat de spoorafbeelding een lineaire afbeelding is \footnote{Zie Voorbeeld 4.4 p 131 9.}.
\[
= Tr(\lambda_1V_1^T\cdot W + \lambda_2V_2^T\cdot W)
= \lambda_1Tr(V_1^T\cdot W) + \lambda_2Tr(V_2^T\cdot W)
= \lambda_1\langle V_1, W\rangle + \lambda_2\langle V_2, W\rangle
\]
Samengevat staat hierboven het volgende, wat precies betekent dat het gegeven inproduct lineair is in de eerste component.

\item Symmetrie\\
\[
\langle V,W\rangle = Tr(V^T\cdot W) = Tr(V\cdot W^T) = \langle V,W\rangle
\]

\item Positief\\
\[
\langle V,V\rangle = Tr(V^T\cdot V)
= \sum_{i=1}^n(V^T\cdot V)_{ii}
= \sum_{i=1}^n\sum_{j=1}^nV^T_{ij}V_{ji} \ge 0
\]

\item Definiet\\
\[
\langle V,V\rangle
= 0 \Leftrightarrow V=\vec{0}
\]
\begin{itemize}
\item $\Rightarrow$\\
\[
\langle V,V\rangle
= 0 \Rightarrow \sum_{i=1}^n\sum_{j=1}^nV^T_{ij}V_{ji} = 0 \Rightarrow V = \vec{0}
\]

\item $\Leftarrow$\\
\[
v = \vec{0} \Rightarrow \langle V,V\rangle = \langle \vec{0},\vec{0}\rangle
= \sum_{i=1}^n\sum_{j=1}^n\vec{0}_{ij}\vec{0}_{ji} = 0
\]

\end{itemize}

\end{itemize}
\end{proof}
\subsubsection*{Extra}
\[
\Vert A_1 \Vert 
= 1
\]
\[
\Vert A_2 \Vert 
= \sqrt{5}
\]
\[
\Vert A_3 \Vert
= \sqrt{14}
\]
\[
\Vert A_4 \Vert
= 2
\]
\[
\langle A_1,A_2 \rangle
= 2
\]
%TODO Inproducten
\[
\langle A_1,A_3 \rangle
=
\]
\[
\langle A_1,A_4 \rangle
=
\]
\[
\langle A_2,A_3 \rangle
=
\]
\[
\langle A_2,A_4 \rangle
=
\]
\[
\langle A_3,A_4 \rangle
=
\]
%TODO hoeken
\[
\widehat{A_1,A_2}
= \arccos\frac{2}{1\cdot \sqrt{5}}
= \arccos\frac{2\sqrt{5}}{5}
\]
\[
\widehat{A_1,A_3}
=
\]
\[
\widehat{A_1,A_4}
=
\]
\[
\widehat{A_2,A_3}
=
\]
\[
\widehat{A_3,A_4}
=
\]
%TODO afstanden
\[
\Vert A_2-A_1 \Vert
=
\]
\[
\Vert A_3-A_1 \Vert
=
\]
\[
\Vert A_4-A_1 \Vert
=
\]
\[
\Vert A_3-A_2 \Vert
=
\]
\[
\Vert A_4-A_3 \Vert
=
\]


\subsection{Oefening 3}
\[
\beta = \{ (3,-3,0),(2,2,-1),(1,1,4) \}
\]
Eerst bepalen we of $\beta$ orthogonaal is.
In de volgende gelijkheden zien we dat dit klopt.
\[
\langle (3,-3,0),(2,2,-1) \rangle = 6-6+0 = 0
\]
\[
\langle (2,2,-1),(1,1,4) \rangle = 2+2-4 = 0
\]
\[
\langle (3,-3,0),(1,1,4) \rangle = 3-3+0 = 0
\]
Vervolgens bepalen we of $\beta$ inderdaad een basis vormt voor $\mathbb{R}^3$.
Omdat $\beta$ precies drie vectoren bevat moeten we enkel aantonen dat $\beta$ vrij is \footnote{Zie Stelling 3.41 p 109.}.
\[
\begin{vmatrix}
3 & -3 & 0\\
2 & 2 & -1\\
1 & 1 & 4
\end{vmatrix}
=
3 \cdot 
\begin{vmatrix}
2 & -1\\
1 & 4
\end{vmatrix}
+ 3 \cdot
\begin{vmatrix}
2 & -1\\
1 & 4
\end{vmatrix}
=
3(8+1)+3(8+1)
=54 \neq 0
\]
Bovenstaande determinant toont aan dat $\beta$ vrij is.


\subsection{Oefening 4}
Stel dat $v=(a,b,c)$ een vector is die orthogonaal is met zowel $(1,2,0)$ als $(1,0,1)$, dan geldt voor $v$ het volgende.
\[
\left\{
\begin{array}{c}
\langle (a,b,c) , (1,2,0) \rangle = 0\\
\langle (a,b,c) , (1,0,1) \rangle = 0
\end{array}
\right.
\]
\[
\left\{
\begin{array}{c}
a + 2b + 0 = 0\\
a + 0 + c = 0
\end{array}
\right.
\]
Dit komt overeen met een homogeen stelsel dat beschreven wordt door de volgende matrix.
\[
\left(
\begin{array}{c c c | c}
1 & 2 & 0 & 0\\
1 & 0 & 1 & 0
\end{array}
\right)
\]
Hiervan bepalen we de oplossingen. We kunnen die aflezen nadat we de matrix te rijreduceren.
\[
\rightarrow
\left(
\begin{array}{c c c | c}
1 & 0 & 1 & 0\\
0 & 2 & -1 & 0
\end{array}
\right)
\]
Hieruit lezen we de volgende oplossingsverzameling af.
\[
\left\{
(-\lambda,\frac{\lambda}{2},\lambda)\ |\ \lambda\in\mathbb{R}
\right\}
\]


\subsection{Oefening 5}
Vooreerst normeren we $(1,2,0)$. Dit doen we door deze vector te delen door zijn lengte.
\[
\beta_1 = \frac{(1,2,0)}{\Vert(1,2,0)\Vert}
= \left(\frac{\sqrt{5}}{5},\frac{2\sqrt{5}}{5},0\right)
\]
\[
\beta_2' = (1,0,1) - \left\langle (1,0,1),\beta_1 \right\rangle \beta_1
= (1,0,1) - \left(\frac{\sqrt{5}}{5},0,0\right)\left(\frac{\sqrt{5}}{5},\frac{2\sqrt{5}}{5},0\right)
\]
\[
=(1,0,1) - (5,0,0) = (4,0,-1)
\]
Nu kunnen we $\beta_2'$ ook normeren tot $\beta_2$.
\[
\beta_2 = \frac{(4,0,-1)}{\Vert (4,0,-1)\Vert}
= \left( \frac{4\sqrt{17}}{17},0,\frac{-\sqrt{17}}{17} \right)
\]
Vervolgens zoeken we $\beta_3'$ als volgt.
\[
\beta_3'
= (2,3,1)
- \left\langle (2,3,1),\beta_1\right\rangle\beta_1
- \left\langle (2,3,1),\beta_2\right\rangle\beta_2
\]
\[
= (2,3,1)
- \left(7\frac{\sqrt{5}}{5}\right)  \beta_1
- \left(7\frac{\sqrt{17}}{17} \right)  \beta_2
\]
\[
=(2,3,1)
- \left(\frac{7}{5},\frac{14}{5},0\right)
- \left( \frac{28}{17},0,\frac{-7}{17} \right)
= 
\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)
\]
Tenslotte normeren we $\beta_3'$ nog tot $\beta_3$.
\[
\beta_3 = 
\frac{\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)}
{\Vert\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)\Vert}
= 
\frac{\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)}
{\frac{89^2}{85^2}+\frac{1}{5^2}+\frac{10^2}{17^2}}
=
\frac{\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)}
{\frac{7921}{7225}+\frac{1}{25}+\frac{100}{289}}
=
\frac{85}{126}
\left(-\frac{89}{85},\frac{1}{5},\frac{10}{17}\right)
=
\frac{1}{126}
\left(-89,17,50\right)
\]
We hebben nu $\alpha$ georthonormaliseerd tot $\beta$.
\[
\beta
=
\left\{
\frac{1}{5}
\left(\sqrt{5},2\sqrt{5},0\right)
,
\frac{1}{17}
\left( 4\sqrt{17},0,-\sqrt{17} \right)
,
\frac{1}{126}
\left(-89,17,50\right)
\right\}
\]

\subsection{Oefening 7}
We zoeken drie orthonormale vectoren $v_1,v_2,v_3$ die aan de gegeven vergelijking $x+2y+z = 0$.
\[
v_i =
\begin{pmatrix}
x_i\\y_i\\z_i
\end{pmatrix}
\]
\[
\forall i,j\in \{1,2,3\}:\ \langle v_i,v_j\rangle = 0
\]
\[
\forall i\in \{1,2,3\}:\ \Vert v_i\Vert = 1
\]
Elke $v_1$ is van de vorm $(\mu - 2\lambda,\lambda,\mu)$ omdat ze aan $x+2y+z=0$ voldoet.
%TODO

\subsection{Oefening 8}
\subsubsection*{(a)}
We zoeken een deelruimte $D$ van $\mathbb{R}^3$ waarvoor geldt dat elk er van loodrecht staat op elk element in $U_1$. Een willekeurige vector $(a,b,c)$ moet dus voldoen aan volgend stelsel.
\[
\langle (a,b,c),(1,1,1)\rangle = 0
\]
\[
\langle (a,b,c),(1,1,0)\rangle = 0
\]
Of nog het volgend.
\[
\left\{
\begin{array}{c c}
a+b+c=0\\
a+b=0
\end{array}
\right.
\]
Bovenstaand stelsel komt overeen met een matrix, die we rijreduceren.
\[
\left(
\begin{array}{c c c  | c}
1&1&1&0\\
1&1&0&0
\end{array}
\right)
\rightarrow
\left(
\begin{array}{c c c  | c}
1&1&0&0\\
0&0&1&0
\end{array}
\right)
\]
In deze matrix lezen we de volgende oplossingsverzameling af.
\[
\{ (-\lambda,\lambda,0)\ |\ \lambda\in\mathbb{R}\}
\]


\subsubsection*{(b)}
We zoeken een deelruimte $D$ van $\mathbb{R}^3$ waarvoor geldt dat elk er van loodrecht staat op elk element in $U_2$. Een willekeurige vector $(a,b,c)$ moet dus voldoen aan volgend stelsel.
\[
\langle (a,b,c),(1,1,1)\rangle = 0
\]
Of nog het volgende stelsel
\[
\left\{
\begin{array}{c c}
a + b + c = 0 
\end{array}
\right.
\]
Intu\"itief zien we al dat dit een vlak is dat loodrecht staat op de rechte $U_2$.
\[
\left(
\begin{array}{c c c | c}
1 & 1 & 1 & 0 
\end{array}
\right)
\]
Hieruit volgt de volgende oplossingsverzameling.
\[
\{ (-\lambda - \mu , \lambda, \mu)\ |\ \lambda,\mu \in \mathbb{R}\}
\]


\subsubsection*{(c)}
We zoeken voor de deelruimte bepaald door $vct\{\bigl(\begin{smallmatrix}
1 & 0 \\
1 & 2
\end{smallmatrix}\bigr),\bigl(\begin{smallmatrix}
1 & 1 \\
1 & 1
\end{smallmatrix}\bigr),\bigl(\begin{smallmatrix}
2 & 2 \\
0 & 1
\end{smallmatrix}\bigr)\}$  het orthogonaal complement. Dit betekent dat we een andere deelruimte van $\mathbb{R}^{2\times2}$ zoeken waarvoor elk element loodrecht staat op de elementen uit de originele vectorruimte.

Deze wordt dus voortgebracht door een vector of alle vectoren $\bigl(\begin{smallmatrix}
a & b \\
c & d
\end{smallmatrix}\bigr)$ die voldoen aan:
\[ <\bigl(\begin{smallmatrix}
a & b \\
c & d
\end{smallmatrix}\bigr),\bigl(\begin{smallmatrix}
1 & 0 \\
1 & 2
\end{smallmatrix}\bigr)> = 0\]
\[ <\bigl(\begin{smallmatrix}
a & b \\
c & d
\end{smallmatrix}\bigr),\bigl(\begin{smallmatrix}
1 & 1 \\
1 & 1
\end{smallmatrix}\bigr)> = 0\]
\[ <\bigl(\begin{smallmatrix}
a & b \\
c & d
\end{smallmatrix}\bigr),\bigl(\begin{smallmatrix}
2 & 2 \\
0 & 1
\end{smallmatrix}\bigr)> = 0\]

Wat betekent dat een element van onze nieuwe deelruimte loodrecht staat op alle elementen van de basis van de oude, en dus ook op al hun lineaire combinaties. Dit geldt door de definitie van het standaardinproduct in $\mathbb{R}^{2\times2}$ als en slechts als:
\[\left\{
\begin{array}{l}
a+c+2*d=0\\
a+b+c+d=0\\
2*a+2*b+d=0
\end{array} \right.\]
We kunnen dit stelsel van gelijkheden omzetten in de matrix
\[\left(
\begin{array}{c c c c | c}
1 & 0 & 1 & 2 & 0\\
1 & 1 & 1 & 1 & 0\\
2 & 2 & 0 & 1 & 0
\end{array}
\right)\]
hetgeen we door rijreductie omzetten in
\[\left(
\begin{array}{c c c c | c}
1 & 0 & 0 & \frac{3}{2} & 0\\
0 & 1 & 0 & -1 & 0\\
0 & 0 & 1 & \frac{1}{2} & 0
\end{array}
\right)\]

Kiezen we $d$ als vrije variabele, dan moeten alle elementen van de nieuwe deelruimte voldoen aan het voorschrift $\bigl(\begin{smallmatrix}
\frac{-3}{2}*\lambda & \lambda \\
\frac{-1}{2}*\lambda & \lambda
\end{smallmatrix}\bigr)$ met $\lambda \in \mathbb{R}$.

We kunnen dus door een invulling van lambda stellen dat het orthogonaal complement de deelruimte is met als voorschrift:
\[
vct\{\bigl(\begin{smallmatrix}
-3 & 2 \\
-1 & 2
\end{smallmatrix}\bigr)\}
\]

\subsection{Oefening 9}
\subsubsection*{(a)}
\[
\alpha=
\left\{
A \in \mathbb{R}^{n\times n}\ |\ A \text{ is symmetrisch}
\right\}^\bot
\]
\[
\beta=
\left\{
A \in \mathbb{R}^{n\times n}\ |\ A \text{ is scheefsymmetrisch}
\right\}
\]
Kies een willekeurig element $B$ uit $\alpha$. Nu geldt voor elk element $A\in\alpha^\bot$ het volgende.
\[
A=A^T\text{ en } Tr(A^TB) = Tr(A^TB^T)= 0
\]
Voor elk element $C \in \beta$ geldt het volgende.
\[
-C = C^T
\]
Het is eenvoudig te zien dat $C$ inderdaad loodrecht staat op $A$.
\[
Tr(C^TA) = Tr(-CA)
\]
Maar ook:
\[
Tr(C^TA) = Tr(CA^T) = Tr(CA)
\]
Dit kan enkel als beide sporen nul zijn.



\subsection{Oefening 10}
Zij $A \in \mathbb{R}^{2\times 2}$ een scheefsymmetrische matrix.
\[
\begin{pmatrix}
0 & a\\
-a & 0
\end{pmatrix}
\]

\subsubsection*{Te Bewijzen}
$A$ heeft geen re\"ele eigenwaarden.

\subsubsection*{Bewijs}
\begin{proof}
Bewijs uit het ongerijmde.\\
Stel dat $\lambda$ een re\"ele eigenwaarde is van $A$ met bijhorende eigenvector $v = \begin{pmatrix}v_1\\v_2\end{pmatrix}$.
\[
\begin{pmatrix}
0 & a\\
-a & 0
\end{pmatrix}
\begin{pmatrix}v_1\\v_2\end{pmatrix}
=\lambda 
\begin{pmatrix}v_1\\v_2\end{pmatrix}
\]
\[
\begin{pmatrix}
v_2\\-v_1
\end{pmatrix}
=
\begin{pmatrix}
\lambda v_1\\\lambda v_2
\end{pmatrix}
\]
\[
\left\{
\begin{array}{c c}
v_2 &= \lambda v_1\\
v_1 &= -\lambda v_2
\end{array}
\right.
\]
\[
\left\{
\begin{array}{c c}
v_2 &= \lambda v_1\\
v_1 &= -\lambda^2 v_1
\end{array}
\right.
\]
Let op de tweede vergelijking in bovenstaand stelsel. Dit stelsel kan enkel gelden indien $-\lambda^2 = 1$ geldt. Het is dus steeds strijdig als $\lambda$ re\"el is. Contradictie.+
\end{proof}


\subsection{Oefening 12}
We kunnen $a$ in het voorschrift vervangen door $B$ waarbij $B$ de volgende matrix is.
\[
B=
\begin{pmatrix}
a & 0 & \cdots & 0\\
0 & a & \cdots & 0\\
\vdots & \vdots& \ddots & \vdots\\
0 & 0 & \cdots & a
\end{pmatrix}
\]
Nu ziet $T$ er als volgt uit ten opzichte van de standaardbasis. ($B$ is de matrix van $T$ ten opzichte van de standaardmatrix.)
\[
T: A \mapsto BA
\]
Zodat $B$ een orthogonale matrix zou zijn moeten volgende gelijkheden gelden.
\[
B^{-1}=
\begin{pmatrix}
\frac{1}{a} & 0 & \cdots & 0\\
0 & \frac{1}{a} & \cdots & 0\\
\vdots & \vdots& \ddots & \vdots\\
0 & 0 & \cdots & \frac{1}{a}
\end{pmatrix}
=
\begin{pmatrix}
a & 0 & \cdots & 0\\
0 & a & \cdots & 0\\
\vdots & \vdots& \ddots & \vdots\\
0 & 0 & \cdots & a
\end{pmatrix}
= B^T
\]
Wanneer we dit oplossen vinden we dat $a$ gelijk moet zijn aan $1$.

\subsection*{Oefening 13}
Zij $A$ en $A'$ de matrices van respectievelijk $T$ en $T'$ ten opzichte van $\beta$.
\[
A^T = A^{-1}
\]
\[
A'^T = A^{-1}
\]

\subsubsection*{Te Bewijzen}
De matrixvoorstelling van $T'\circ T$ ten opzichte van $\beta$ is orthogonaal
\[
(A'\cdot A)^T = (A'\cdot A)^{-1} 
\]

\subsubsection*{Bewijs}
\begin{proof}
\[
(A'A)^T = A^TA'^T = A^{-1}A'^{-1} = (A'\cdot A)^{-1} 
\]
Zie de eigenschappen van getransponeerde matrices \footnote{Zie Eigenschap 1.22 p 31 (c)} en inverse matrices \footnote{Zie Stelling 1.32 p 35}.
\end{proof}


\subsection{Oefening 14}
\subsubsection*{(a)}
\[
A = 
\begin{pmatrix}
1 & 2 & 0\\
2 & 2 & 2\\
0 & 2 & 3\\
\end{pmatrix}
\]
We zoeken eerst de eigenwaarden van de $A$, dit zijn $\{-1,2,5\}$.
We zoeken nu bij elk van deze eigenwaarden een genormeerde eigenvector, maar daarvoor moeten we eerst de eigenruimten van elk van deze eigenwaarden bepalen.
\begin{itemize}
\item $E_{-1}$
\[
\begin{pmatrix}
2 & 2 & 0\\
2 & 3 & 2\\
0 & 2 & 4\\
\end{pmatrix}
\rightarrow
\begin{pmatrix}
1 & 0 & -2\\
0 & 1 & 2\\
0 & 0 & 0\\
\end{pmatrix}
\]
\[
E_{-1} = 
\left\{ 
\lambda
\begin{pmatrix}
2 \\ -2\\ 1
\end{pmatrix}
| \lambda \in \mathbb{R}
\right\}
\]

\item $E_{2}$
\[
\begin{pmatrix}
-1 & 2 & 0\\
2 & 0 & 2\\
0 & 2 & 1\\
\end{pmatrix}
\rightarrow
\begin{pmatrix}
1 & 0 & 1\\
0 & 1 & \frac{1}{2}\\
0 & 0 & 0\\
\end{pmatrix}
\]
\[
E_{2} = 
\left\{ 
\lambda
\begin{pmatrix}
-1 \\ -\frac{1}{2} \\ 1
\end{pmatrix}
| \lambda \in \mathbb{R}
\right\}
\]

\item $E_{5}$
\[
\begin{pmatrix}
-4 & 2 & 0\\
2 & -3 & 2\\
0 & 2 & -2\\
\end{pmatrix}
\rightarrow
\begin{pmatrix}
1 & 0 & -\frac{1}{2}\\
0 & 1 & -1\\
0 & 0 & 0\\
\end{pmatrix}
\]
\[
E_{5} = 
\left\{ 
\lambda
\begin{pmatrix}
\frac{1}{2} \\ 1 \\ 1
\end{pmatrix}
| \lambda \in \mathbb{R}
\right\}
\]
\end{itemize}
We zoeken nu een genormeerde eigenvector uit elke eigenruimte.
\[
\left\Vert
\lambda
\begin{pmatrix}
2 \\ -2\\ 1
\end{pmatrix}
\right\Vert
=1
\Leftrightarrow
\lambda = \frac{\sqrt{5}}{5}
\]
\[
\left\Vert
\lambda
\begin{pmatrix}
-1 \\ -\frac{1}{2} \\ 1
\end{pmatrix}
\right\Vert
=1
\Leftrightarrow
\lambda = \frac{3}{2}
\]
\[
\left\Vert
\lambda
\begin{pmatrix}
\frac{1}{2} \\ 1 \\ 1
\end{pmatrix}
\right\Vert
=1
\Leftrightarrow
\lambda = \frac{3}{2}
\]
Werken we dit uit, dan vinden we volgende orthonormale basis van eigenvectoren.
\[
\left\{
\begin{pmatrix}
\frac{2\sqrt{5}}{5} \\ -\frac{2\sqrt{5}}{5}\\ \frac{\sqrt{5}}{5}
\end{pmatrix}
,
\begin{pmatrix}
-\frac{3}{2} \\ -\frac{3}{4} \\ \frac{3}{2}
\end{pmatrix}
,
\begin{pmatrix}
\frac{3}{4} \\ \frac{3}{2} \\ \frac{3}{2}
\end{pmatrix}
\right\}
\]
Zetten we nu deze vectoren als kolommen in een matrix, dan is deze matrix een orthogonale matrix en wel precies de $P$ die we zoeken.
\[
P=
\begin{pmatrix}
\frac{2\sqrt{5}}{5}  & -\frac{3}{2} & \frac{\sqrt{5}}{5}\\ 
-\frac{2\sqrt{5}}{5} & -\frac{3}{4} & \frac{3}{2}\\ 
\frac{\sqrt{5}}{5} & \frac{3}{2}    & \frac{3}{2}
\end{pmatrix}
\]


\subsubsection*{(b)}


\subsubsection*{(c)}

\subsection{Oefening 18}
\label{oef:6.18}
\[U^{\bot_{\mathbb{R}^n}} + W = \begin{pmatrix} W^{\bot_U} \end{pmatrix}^{\bot_{\mathbb{R}^n}}.\]
\begin{proof}
Kies $v \in U^{\bot_{\mathbb{R}^n}} + W$ en $w^{\bot_U} \in W^{\bot_U}$ willekeurig. We zien dat $v = u^{\bot} + w$, geld waarbij $u^{\bot} \in U^{\bot_{\mathbb{R}^n}}$ en $w \in W$ geldt.\\
Aangezien $w \in W$ en $w^{\bot} \in W^{\bot_U}$ gelden, geldt $\langle w, w^{\bot} \rangle = 0$. We weten ook dat $u^{\bot} \in U^{\bot_{\mathbb{R}^n}}$ geldt, dus $u^{\bot}$ staat loodrecht op elk element van $U$. We weten echter dat $W^{\bot_u} \subset U$, dus geldt ook $\langle u^{\bot}, w^{\bot} \rangle = 0$. Hieruit volgt nu
\[\langle v, w^{\bot} \rangle = 0\]
voor elke $v \in U^{\bot_{\mathbb{R}^n}} + W$ en $w^{\bot_U} \in W^{\bot_U}$. Dit betekent dat
\[(W^{\bot_U})^{\bot_{\mathbb{R}^n}} \subseteq U^{\bot_{\mathbb{R}^n}} + W.\]
We bewijzen nu dat de dimensies gelijk zijn. Zij $\dim(W \cap U^{\bot_{\mathbb{R}^n}}) = r$, $\dim W = k$, $\dim(U^{\bot_{\mathbb{R}^n}}) = l$ en $\dim(U) = n - l$. We zien nu:
\[\dim(U^{\bot_{\mathbb{R}^n}} + W) = \dim(U^{\bot_{\mathbb{R}^n}}) + \dim W - \dim(U^{\bot_{\mathbb{R}^n}}) = k + l - r.\]
Voor de dimensie van het rechterlid krijgen we
\[\dim \begin{bmatrix} \begin{pmatrix} W^{\bot_u} \end{pmatrix}^{\bot_{\mathbb{R}^n}} \end{bmatrix} = \dim \mathbb{R}^n - \dim(W^{\bot_u})\]
\[= n - \begin{bmatrix} \dim U - \dim W + \dim \begin{pmatrix} W \cap U^{\bot_{\mathbb{R}^n}} \end{pmatrix} \end{bmatrix} = n - \begin{bmatrix} (n - l) - k + r \end{bmatrix} = l + k - r.\]
We zien dus dat de deelruimten dezelfde dimensie hebben en dat de ene deelruimte een deelverzameling is van de andere. Hieruit volgt dat ze gelijk zijn. \end{proof}


\section{Opdrachten}

\subsection{Opdracht 6.8 p 227}
\label{6.8}
Kies willekeurige elementen $x_1,x_2,x,y \in \mathbb{R}^{2}$ en $\lambda_1,\lambda_2,\lambda \in \mathbb{R}$.
\begin{enumerate}
\item
\begin{proof}
\begin{enumerate}
\item Lineair in de eerste component
\[
\langle \lambda_1x_1 + \lambda_2x_2,y \rangle_1
\]
\[
= 3(\lambda_1x_1 + \lambda_2x_2)_1y_1 - 2(\lambda_1x_1 + \lambda_2x_2)_1y_2-2(\lambda_1x_1 + \lambda_2x_2)_2y_1+2(\lambda_1x_1 + \lambda_2x_2)_2y_2
\]
\[
= \lambda_1(3x_{11}y_1-2x_{11}y_2-2x_{12}y_1+2x_{12}y_2) + \lambda_2(3x_{21}y_1-2x_{21}y_2-2x_{22}y_1+2x_{22}y_2)
\]
\[
= \lambda_1\langle x_1,y \rangle_1
+  \lambda_2\langle x_2,y \rangle_1
\]

\item Symmetrisch
\[
\langle x , y \rangle_1
=
3x_{1}y_1-2x_{1}y_2-2x_{2}y_1+2x_{2}
= \langle y , x \rangle_1
\]

\item Positief
\[
\langle x,x \rangle_1  = x_1^2 + x_2^2\ge 0
\]

\item Definiet
\[
\langle x,x \rangle_1 = 0 \Leftrightarrow x= \vec{0}
\]

\begin{itemize}
\item $\Rightarrow$
\[
\langle x,x \rangle_1 = 0 
\]
\[
x_1^2=0
\]
\[
\Rightarrow x= \vec{0}
\]

\item $\Leftarrow$
\[
x= \vec{0}
\]
\[
x_1^2=0
\]
\[
 \Rightarrow \langle x,x \rangle_1 = 0
\]
\end{itemize}
\end{enumerate}
\end{proof}

\item
Dit inproduct is niet positief. 
Kies bevoorbeeld $x$ als volgt.
\[
x = 
\begin{pmatrix}
1\\1
\end{pmatrix}
\]
\[
\langle x,x \rangle_1 = -1 <0
\]
\end{enumerate}




\end{document}