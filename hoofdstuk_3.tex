\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\part{Hoofdstuk 3}

\section{Bewijzen uit het boek}
\subsection{Stelling 3.49}
\subsubsection*{Te Bewijzen}
Als de vectorruimte V eindigdimensionaal is, dan geldt voor willekeurige deelruimten $U$ en $W$ van $V$ het volgende.
\[
dim(U+W) + dim(U\cap W) = dim(U) + dim(W)
\]
\subsubsection*{Bewijs}
We willen een verband vinden tussen de dimensies van al deze verzamelingen ($(U+W)$, $U\cap W$, $U$ en $W$). Om dit te doen beginnen we met een basis van de kleinste verzameling ($U \cap W$). Daarna breiden we deze basis uit tot een basis van $U$, tot een basis van $W$ en tot een basis van $(U + W)$. De dimensie van een vectorruimte is gelijk aan het aantal elementen in de basis ervan.\footnote{Definitie 3.35 p 106}\\\\
Zij $dim(U) = r$, $dim(W)=s$ en $dim(U\cap W) = t$.
\begin{proof}
Ingewikkeld bewijs.\\
$U$ en $W$ zijn beide een deelruimte van $V$, dus $(U \cap W)$ is ook een deelruimte van $V$ \footnote{Propositie 3.14 p 96}. Omdat $(U \cap W)$ een deelruimte is van $V$, zal $t \le r$ en $t \le s$. We nemen een basis van $(U\cap W)$ en noemen deze $\beta = \{v_1,...,v_n\}$.Om $\beta$ uit te breiden tot een basis $\beta_U$ van $U$ moet we $r-t$ vectoren toe voegen. Om $\beta$ uit te breiden tot een basis $\beta_W$ van $W$ moeten we $s-t$ vectoren toe.\\
De basisvectoren van $U$ zijn dus $\{v_i,...,v_t,u_{t+1},...,u_r\}$. Bovendien zijn de basisvectoren van $W$, $\{v_i,...,v_t,w_{t+1},...,w_k\}$.
We willen bewijzen dat de basis $\beta_U \cup \beta_W = \{v_1,...,v_t,u_{t+1},...,u_{r},w_{t+1},...,w_{s}\}$ een basis is van $U+W$.
Een basis van een vectorruimte is vrij en voortbrengend. We bewijzen deze eigenschappen appart.\\
\textbf{Vrij}\\
Neem een willekeurige lineaire combinatie van de basisvectoren van $(U+W)$.
\[
0 = \sum_{i=1}^tx_iv_i + \sum_{j=t+1}^ry_ju_j + \sum_{k=t+1}^sz_kw_k
\]
Om te bewijzen dat de $\beta_U \cup \beta_W$ vrij is, moeten we bewijzen dat alle $v_i,y_j,z_k$ nul zijn.\\
De vector $\sum_{k=t+1}^sz_kw_k \in W$ zit in $W$ omdat alle $w_k \in W$. Bovendien kan deze vector geschreven worden als volgt.
\[
\sum_{k=t+1}^sz_kw_k = -\sum_{i=1}^tx_iv_i - \sum_{j=t+1}^ry_ju_j
\]
Deze vector zit bijgevolg in $U$ en dus ook in $U\cap W$ want ze valt te schrijven als een lineaire combinatie van de basisvectoren van $U$ ($\beta_U$).
Omdat $\sum_{k=t+1}^sz_kw_k \in (U\cap W)$ is de volgende bewering waar.
\[
\exists \lambda_i \in \mathbb{R} \sum_{k=t+1}^sz_kw_k = \sum_{i=1}^t\lambda_iv_i
\]
\[
\exists \lambda_i \in \mathbb{R} \sum_{k=t+1}^sz_kw_k - \sum_{i=1}^t\lambda_iv_i = 0 
\]
Het linkerlid van de bovenstaande vergelijking is een lineaire combinatie van de basisvectoren van $W$. Van deze basisvectoren weten we dat ze lineair onafhankelijk zijn, dus moeten alle $z_k, \lambda_i$ nul zijn. We weten nu dus al dat alle $z_k$ in de originele vergelijking nul zijn.\\
Dezelfde redenering kunnen we toepassen op de vector $\sum_{j=t+1}^ry_ju_j \in U$. Deze vector kan geschreven worden als volgt.
\[
\sum_{j=t+1}^ry_ju_j= -\sum_{i=1}^tx_iv_i - \sum_{k=t+1}^sz_kw_k
\]
Deze vector zit dus in $W$ en bijgevolg ook in $(U\cap W)$ want ze valt te schrijven als een lineaire combinatie van de basisvectoren $W$ ($\beta_W$). Omdat $\sum_{j=t+1}^ry_ju_j \in (U\cap W)$ is de volgende bewering waar.
\[
\exists \lambda_i \in \mathbb{R} \sum_{j=t+1}^ry_ju_j = \sum_{i=1}^t\lambda_iv_i
\]
\[
\exists \lambda_i \in \mathbb{R} \sum_{j=t+1}^ry_ju_j - \sum_{i=1}^t\lambda_iv_i = 0 
\]
Het linkerlid van de bovenstaande vergelijking is een lineaire combinatie van de basisvectoren van $W$. We weten dat deze lineair onafhankelijk zijn, dus moeten alle $y_j,  \lambda_i$ ook nul zijn.\\
In de eerste vergelijking weten we nu al dat alle $z_k,y_j$ nul zijn. Nu blijft er dus nog het volgende over.
\[
0 = \sum_{i=1}^tx_iv_i + 0 + 0
\]
Het rechterlid van deze vergelijking is een lineaire combinatie van de basisvectoren van $U\cap W$. Van deze vectoren weten we dat ze lineair onafhankelijk zijn, dus alle $x_i$ moeten nul zijn.
Nu hebben we bewezen dat $\beta_U\cup \beta_W$ een basis is van $U+W$
\textbf{Voortbrengend}\\
Om te bewijzen dat een basis voortbrengend is voor een vectorruimte nemen we een willekeurig element uit te vectorruimte en tonen we aan dat het een lineaire combinatie is van de basis.
Neem een willekeurig element $x \in (U + W)$. We tonen de volgende bewering aan.
\[
\exists x_i,y_j,z_k \in \mathbb{R}: x = \sum_{i=1}^tx_iv_i + \sum_{j=t+1}^ry_ju_j + \sum_{k=t+1}^sz_kw_k
\]
We weten ook dat $\exists u\in U, w\in W: x = u+w$. De volgende bewering geldt dus zeker.\footnote{Definitie 3.19 p 98}
\[
\exists x_a,x_b,y_j,z_k \in \mathbb{R}  u+w = \sum_{a=1}^tx_av_a + \sum_{j=t+1}^ry_ju_j + \sum_{b=1}^tx_bv_b + \sum_{k=t+1}^sz_kw_k
\]
Kiezen we nu de $x_a,x_b$ zodat de volgende bewering geldt.
\[
\sum_{i=1}^tx_iv_i = \sum_{a=1}^tx_av_a + \sum_{b=1}^tx_bv_b 
\]
Nu is aangetoond dat $\beta_U \cup \beta_W$ voortbrengend is.
\\\\ 
We weten nu dat $\beta_U \cup \beta_W$ een basis is van $U+W$. De basis van $\beta_U \cup \beta_W$ bevat precies $(r-t)+(s-t)+t = r+s-t$ basisvectoren. Als we nu terug kijken naar de benaming van de dimensies van $U$, $W$ en $U\cap W$ zien we het volgende.
\[
dim(U+W) r+s-t = dim(U) + dim(W) + dim(U \cap W)
\]
\end{proof}

\section{Oefeningen 3.6}

\subsection{oef 1}
\subsubsection*{b)}
distributiviteit-2 geldt niet.
\[
(\lambda_1 + \lambda_2)v = \lambda_1v = \lambda_2v
\]
en niet
\[
(\lambda_1 + \lambda_2)v = \lambda_1v+\lambda_2v
\]

\subsubsection*{c)}
optelling is niet commutatief.
\[
(x_1,y_1) + (x_2,y_2) = (x_1+2x_2,y_1+2y_2)
\]
\[ \neq \]
\[
(x_2,y_2) + (x_1,y_1) = (x_2+2x_1,y_2+2y_1)
\]

\subsection{oef 2}
\subsubsection*{a)}
Deze verzameling vormt de unie van de drie vlakken rond de assen. Dit is geen deelruimte want de optelling is niet intern.\\
\underline{Tegenvoorbeeld:}\\
\[
(1,0,0) + (0,1,1) = (1,1,1) \not \in W_1
\]
\subsubsection*{b)}
$W_2$ is geen deelruimte van $\mathbb{R}^{3}$.\\
\underline{Tegenvoorbeeld:}\\
$x = (3, 4, 5) \in W_2$ en $y = (2, 2, \sqrt{8}) \in W_2$ maar $x + y = (5, 6, 5 + \sqrt{8}) \not \in W_2$

\subsubsection*{e) }
waar\\
*) $0 \in W_5$ \\
*) $A,B \in W_5 \longmapsto A+B \in W_5$ \\
$ \sum\limits_{i=1,j=1}^a (A+B)_{ij} = \sum\limits_{i=1,j=1}^a A_{ij} + \sum\limits_{i=1,j=1}^a B_{ij} = 0+0 = 0 $ \\
*) $ A \in W_5, \lambda \in R \longmapsto \lambda A \in W_5$ \\
$ \sum\limits_{i=1,j=1}^a (\lambda A)_{ij} = \lambda \sum\limits_{i=1,j=1}^a A_{ij} = \lambda 0 = 0$


\subsubsection*{f)}
$W_6$ is geen deelruimte van $R^{3\times 3}$ want de volgende eigenschap geldt niet: (zie p 94)
\[
\forall x,y\in W_6,\;\forall r,s\in\mathbb{R}:\; r\cdot x+s\cdot y\in U
\]
Tegenvoorbeeld:
stel $x=y$, $r=1$ en $s=-1$.\\
Concreet:
\[
x = I_3
\]

\subsubsection*{g)}
$W_7$ is een deelruimte van $\mathbb{R}^{3x3}$.\\
\begin{proof} 

1) $W_7$ bevat het nulelement. De nulmatrix is immers ook een symmetrische matrix. \\
2) $ Symm(A1) + Symm(A2) = A3 $
	and $A3 = \mathbb{R}^{3x3}$ \\
3) $ \lambda \cdot Symm(A) = A2 $
	and $ A2 = \mathbb{R}^{3x3}$

Er is voldaan aan de drie eigenschappen.

\end{proof}


\subsubsection*{i)}
$W_9$ is geen deelruimte van $R^{3\times 3}$. De optelling is namelijk niet intern.
\[
(0,1,0) + (1,0,0) = (1,1,0) \not \in W_9
\]

\subsubsection*{j)}
$W_{10}$ is geen deelruimte van $R\rightarrow R$ want het neutraal element van $R\rightarrow R$  zit niet in $W_{10}$.
\subsubsection*{l)}
Neem $f, g \in W_{12}$ en $\lambda, \mu \in \mathbb{R}$ willekeurig.\\
Omdat $f$ en $g$ integreerbaar zijn, is $\lambda f + \mu g$ integreerbaar.
\begin{align*}
  \int^1_0 (\lambda f + \mu g)(x)dx &= \int^1_0(\lambda f(x) + \mu g(x))dx\\
  &= \int^1_0 \lambda f(x)dx + \int^1_0 \mu g(x)dx\\
  &= \lambda \int^1_0 f(x)dx + \mu \int^1_0 g(x)dx = \lambda \cdot 0 + \mu \cdot 0 = 0
\end{align*}
$W_{12}$ is dus een deelruimte van $\mathbb{R} \rightarrow \mathbb{R}$.



\subsection*{oef 3}
\subsubsection*{Optelling}
\underline{Associativiteit:}\\
Stel $r_1$, $r_2$, $r_3$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.\\
Dan geldt
\begin{align*}
    (r_1 + r_2) + r_3 &= (a_1 + b_1) + c_1 , (a_2 + b_2) + c_2 , ... , (a_n + b_n)+ c_n\\
    &= a_1 + b_1 + c_1, a_2 + b_2 + c_2, ... , a_n + b_n + c_n\\
    &= a_1 + (b_1 + c_1), a_2 + (b_2 + c_2), ..., a_n + (b_n + c_n)
\end{align*}
\underline{Neutraal element:}\\
We nemen als neutraal element de nulrij 0, met $x_1 = 0, x_2 = 0$ . 
Door de differentievergelijking is ieder volgend element ook nul.\\
Hierdoor geldt dan voor een willekeurige rij r
\begin{align*}
  r + 0 &= a_1 + 0, a_2 + 0, ..., a_n + 0\\
  &= a_1, a_2, ..., a_n\\
  &= r\\
  &= 0 + a_1, 0 + a_2, ..., 0 + a_n\\
  &= 0 + r
\end{align*}
\underline{Tegengesteld element:}\\
Als er een rij $r$ bestaat met $x_1 = a_1$, $x_2 = a_2$, dan kiezen we als tegengesteld element de rij $r'$ met $x_1 = -a_1$ en $x_2 = -a_2$.\\
Hierdoor geldt dan
\begin{align*}
    r + r' &= a_1 - a_1, a_2 - a_2, ...,a_n - a_n\\
    &= 0, 0, ..., 0\\
    &= -a_1 + a_1, -a_2 + a_2, ..., -a_n + a_n\\
    &= r' + r
\end{align*}
\underline{Commutativiteit:}\\
Stel $r_1$, $r_2$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.\\
Dan geldt
\begin{align*}
    r_1 + r_2 &= a_1 + b_1, a_2 + b_2, ..., a_n + b_n\\
    &= b_1 + a_1, b_2 + a_2, ..., b_n + a_n\\
    &= r_2 + r_1
\end{align*}
\subsubsection*{Scalaire vermenigvuldiging}
\underline{Distributiviteit-1:}\\
Stel $r_1$, $r_2$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda \in \mathbb{R}$.
\begin{align*}
    \lambda \cdot(r_1 + r_2) &= \lambda (a_1 + b_1), \lambda (a_2 + b_2), ..., \lambda (a_n + b_n)\\
    &= \lambda a_1 + \lambda b_1, \lambda a_2 + \lambda b_2, ..., \lambda a_n + \lambda b_n\\
    &= \lambda \cdot r_1 + \lambda \cdot r_2
\end{align*}
\underline{Distributiviteit-2:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda_1 , \lambda_2 \in \mathbb{R}$.
\begin{align*}
    (\lambda_1 + \lambda_2) \cdot r &= (\lambda_1 + \lambda_2) a_1, (\lambda_1 + \lambda_2) a_2, ..., (\lambda_1 + \lambda_2) a_n\\
    &= \lambda_1 a_1 + \lambda_2 a_1, \lambda_1 a_2 + \lambda_2 a_2, ..., \lambda_1 a_n + \lambda_2 a_n\\
    &= \lambda_1 \cdot r + \lambda_2 \cdot r
\end{align*}
\underline{Gemengde associativiteit:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda_1 , \lambda_2 \in \mathbb{R}$.
\begin{align*}
    \lambda_1 \cdot (\lambda_2 \cdot r) &= \lambda_1 \cdot (\lambda_2 a_1), \lambda_1 \cdot (\lambda_2 a_2), ..., \lambda_1 \cdot (\lambda_2 a_n)\\
    &= (\lambda_1 \cdot \lambda_2) a_1, (\lambda_1 \cdot \lambda_2) a_2, ..., (\lambda_1 \cdot \lambda_2) a_n\\
    &= (\lambda_1 \cdot \lambda_2) \cdot r
\end{align*}
\underline{Co\"effici\"ent 1:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.
\begin{align*}
     1 \cdot r &= 1 \cdot a_1, 1 \cdot a_2, ..., 1 \cdot a_n\\
     &= a_1, a_2, ..., a_n\\
     &= r
\end{align*}

\subsection*{oef 4}
Welke oef uit de definitie van een vectorruimte zijn voldaan? \\
1. De optelling is inwendig en overal bepaald, ja \\
2. De optelling is associatief,	ja \\
3. Er is een neutr element, ja \\
4. Elk element heeft een tegeng element, ja \\
5. De opt is comm, nee \\

1. Distr-1, \\
2. Distr-2, ja \\
3. gemeng asso, ja\\
4. nee

\subsection{oef 5}
Ja, $W$ is een deelruimte van $R[X]_{\le n}$ als $n\ge 1$.
\subsubsection*{Te bewijzen}
\[
\forall w_1,w_2 \in W,\forall \lambda_1,\lambda_1 \in \mathbb{R}: \lambda_1w_1+\lambda_2w_2 \in W
\]
\subsubsection*{Bewijs}
\begin{proof}
Voor elke $w_1,w_2 \in W, \lambda_1,\lambda_1 \in \mathbb{R}$ geldt dat $ \lambda_1w_1+\lambda_2w_2 \in W$ want $w_1$ en $w_2$ zijn ofwel nul ofwel hebben ze graad $n$. Elke lineaire combinatie zal dus ofwel nul zijn ofwel graad $n$ hebben.
\end{proof}


\subsection{oef 6}
\subsubsection*{Gegeven}
$U$ en $W$ zijn deelruimten van een vectorruimte $(\mathbb{R},V,+)$.
\subsubsection*{Te Bewijzen}
\[
U \cup W \text{ is een deelruimte van }V \Leftrightarrow U \subset W \vee W \subset U
\]
\subsubsection*{Bewijs}
\begin{proof} Samengesteld bewijs.
\\Deel 1: $(\Rightarrow)$
\\ Te bewijzen:
\[
U \cup W \text{ is een deelruimte van }V \Rightarrow U \subset W \vee W \subset U
\]
Bewijs uit het ongerijmde.
\\Stel dat $\neg(U \subset W \wedge W \subset U)$.
\\Dit is equivalent met $U \not\subset W \wedge W \not\subset U$.
Vanuit de definitie van deelverzameling betekent deze bewering het volgende.
\[
(\exists w': w' \in W \wedge w' \not\in U) \wedge (\exists u': u' \in U \wedge u' \not\in W) 
\]
We moeten nu tot een contradictie komen met ``$U\cup W \text{ is een deelruimte van }V$''.
$U\cup W \text{ is een deelruimte van }V$ betekent vanuit de definitie het volgende.
\[
\forall w, u \in Ä‰,\; \forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u + \lambda_2\cdot w \in U\cup W
\]
Aangezien deze bewering geldt voor elke $w,i \in U\cup W$, geldt ze ook voor $w'$ en $u'$.
We weten nu het volgende.
\[
\forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u' + \lambda_2\cdot w' \in U\cup W
\]
met $w' \in W \wedge w' \not\in U$ en $u' \in U \wedge u' \not\in W$.\\
Als dit geldt voor elke $\lambda_1$ en $\lambda_2$, geldt het ook voor $\lambda_1= \lambda_2 = 1$ en geldt dus het volgende.
\[
u' + w' \in U \cup W
\]
We weten dat dit niet klopt, want stel als $u' + w' \in U \cup W$ en $u' \in U$, dan $w' \in U$. Contradictie.
\\Deel 2: $(\Leftarrow)$
\\ Te bewijzen:
\[
U \cup W \text{ is een deelruimte van }V \Leftarrow U \subset W \vee W \subset U
\]
Direct bewijs.\\
Stel $U \subset W$. (Het andere geval is volledig analoog)\\
Als $U \subset W$, dan is $U\cup W = W$. Van $W$ is gegeven dat het een deelruimte is van $W$. Hiermee is bewezen dat $U\cup W$ een deelruimte is van $V$.6
\end{proof}

\subsection*{oef 7}
Om te zien of een vector $d$ tot een deelruimte behoort opgespannen door vectoren $v_1$ en $v_2$ en $v_3$ moeten we zien of er een lineaire combinatie bestaat zodat  $$a\cdot v_1 + b\cdot v_2 + c\cdot v_3 = d$$
Dus:
$$a(2,-1,3,2) + b(-1,1,1,-3) + c(1,1,9,-5) \overset{?}{=} (3,-1,0,-1)$$
We gieten dit in een matrix:
$$
\begin{pmatrix}
2 & -1 & 1 &3\\
-1 & 1 & 1 & -1\\
3 & 1 &9 & 0\\
2 & -3 &-5& -1
\end{pmatrix}
$$
Door rijreductie verkrijgen we volgende matrix:
$$
\begin{pmatrix}
1&0&2&0\\
0&1&3&0\\
0&0&0&1\\
0&0&0&0
\end{pmatrix}
$$
Dit is een ongeldige matrix en dus bestaat er geen lineaire combinatie zodat de vector $d$ gevormd wordt. De vector behoort dus niet tot de deelruimte.

\subsection*{oef 8}
We willen $p(X)$ opschrijven als lineaire combinatie van $p_1(X), p_2(X), p_3(X)$, dus $p(X) = \lambda_1 p_1(X) + \lambda_2 p_2(X) + \lambda_2 p_3(X)$.
Hiervoor lossen we het volgende stelsel op:
\[
\left\{
\begin{array}{l l l l l}
  -1 &= &\lambda_1 &+ 2 \lambda_2 &+ 3 \lambda_3\\
  -3 &= &2 \lambda_1 &+ 5 \lambda_2 &+ 8 \lambda_3\\
  3 &= &\lambda_1 &&- 2 \lambda_3
\end{array}
\right.
\]
Dit vullen we in in een matrix, die we hierna oplossen m.b.v. rijreductie.
\[
\begin{pmatrix}[ccc|c]
  1 & 2 & 3 & -1\\
  2 & 5 & 8 & -3\\
  1 & 0 & -2 & 3
\end{pmatrix}
\rightarrow
\begin{pmatrix}[ccc|c]
  1 & 0 & 0 & -1\\
  0 & 1 & 0 & 3\\
  0 & 0 & 1 & -2
\end{pmatrix}
\]
We resulteren dus dat $p(X) = - p_1(X) + 3 p_2(X) - 2 p_3(X)$.


\subsection*{oef 9}
$$f(x)+g(x)-h(x)+0\cdot exp(x) = 0$$
$$1 - 1 + 0 = 0$$
Dit is een lineaire combinatie waarbij niet alle co\"effi\"enten nul zijn en toch de nulvector als oplossing geeft. Hierdoor is
$\{f,g,h,exp\}$ geen lineair onafhankelijke deelruimte.
\subsection*{oef 12}
Moest dit waar zijn dan mag er uit de verzameling $\{ e_1-e_2,e_2-e_3,\dots ,e_{n-1}-e_n,e_n-e_1\}$ geen enkel element bestaan dat een combinatie is van de andere elementen.
$$
\text{We zien nu voor}\ 1 \leq i \leq n:
$$
$$ 
(e_1-e_2)+(e_2-e_3)+\dots +(e_{i-1}-e_i)+(e_{i+1}-e_{i+2})+\dots + (e_n - e_1)
$$
$$
= (\not e_1-\not e_2+\not e_2-\not e_3+\dots +\not e_{i-1}-e_i+e_{i+1}-\not e_{i+2}+\dots + \not e_n - \not e_1)
$$
$$
= -e_i + e_{i+1}
$$
Dus voor een willkeurige vector:
$$
e_i - e_{i+1} = -\left((e_1-e_2)+(e_2-e_3)+\dots +(e_{i-1}-e_i)+(e_{i+1}-e_{i+2})+\dots + (e_n - e_1)\right)
$$
kunnen we dus telkens een combinatie vinden uit de andere vectoren, hierdoor is het geen vrij deel. 
\subsection*{oef 13}
Hiervoor kunnen we aantonen dat $\{1+X,1+X^2,X+X^2\}$ minimaal voortbrengend is, hiervoor laten we zien dat elke vector uit  $(\mathbb{R},\mathbb{R}[X]_{\leq 2},+)$ een lineaire combinatie is van de basisvectoren:
$$aX^2 + bX + c = \lambda_{1} (1+X) + \lambda_{2} (1+X^2) + \lambda_{3} (X+X^2)$$
Als we deze vergelijking uitwerking uitwerken krijgen we:
$$a = \lambda_{1} + \lambda_2$$
$$b = \lambda_1 + \lambda_3$$
$$c = \lambda_1 + \lambda_2$$
Dit is een stelsel met exact 1 oplossing. Hierme tonen we aan dat het stelsel voortbrengend is en minimaal voortbrengend. Moesten we nog extra vergelijkingen er aan toevoegen zouden we redundantie invoeren of het stelsel onoplosbaar maken.
\\
\\
De co\"ordinaten van de vector $4 -3X + X^2$ kunnen we berekenen ze in een stelsel te gieten:
$$
\begin{pmatrix}
1&1&0&4\\
1&0&1&-3\\
0&1&1&1
\end{pmatrix}
$$
Via rijoperaties verkrijgen we dan:
$$
\begin{pmatrix}
1&0&0&0\\
0&1&0&4\\
0&0&1&-3
\end{pmatrix}
$$
Dit komt overeen met de co\"ordinaten $(0,4,-3)$.
\\
\\
Het co\"ordinatenstel $(2,-3,1)$ komt dan weer overeen met:
$$
2\cdot (1+X) -3 \cdot (1+X^2)+ 1\cdot (X+X^2)= -1 +3X-2X^2
$$

\subsection*{Oefening 16}

Standaard basis : $\beta1 = {e1 =(1,0,0,0), e2 =(0,1,0,0), e3 = (0,0,1,0), e4 = (0,0,0,1) }$

tweede basis : $\beta2 = {f1 = (1,1,1,1), f2 =(0,1,1,1), f3 = (0,0,1,1), f4= (0,0,0,1) }$

volgens $\beta1  V = a1e1 + a2e2 + a3e3 + a4e4$
volgens $\beta2 V = \lambda1 \cdot f1 + \lambda2 \cdot f2 + \lambda3 \cdot f3 + \lambda4 \cdot f4 $ 

$=> (\lambda1, \lambda2, \lambda3, \lambda4) $

\subsection{oef 17}
\subsubsection*{a)}
$W_1$ vormt een vlak. We zoeken twee lineair onafhankelijke vectoren in dat vlak, die zijn dan een basis.
\[
\left\lbrace
\begin{pmatrix}
1\\-2\\1\\
\end{pmatrix}
,
\begin{pmatrix}
2\\-2\\0
\end{pmatrix}
\right\rbrace
\]

\subsubsection*{b)}
Voor de basis te kennen lossen we eerst volgend stelsel op want hieraan moet voldaan zijn:
$$
\begin{pmatrix}[c c c | c]
1 & 2&-1&0\\
2&1&1&0\\
\end{pmatrix}
$$
Hiervoor krijgen we de oplossing $x=-k$, $y= k$, $z=k$. Een oplossing is dus telkens van de vorm $(-k,k,k)$.\\
We krijgen dus als basis:
$$W_2 = \{(-\lambda, \lambda, \lambda)|\lambda \in \mathbb{R}\}$$
De dimensie is dus 1.
\subsection*{oef 19}
\subsubsection*{b)}
\[ A =
\begin{pmatrix}
  1 & 1 & 1\\
  1 & 1 & -1\\
  1 & -1 & 1\\
  1 & -1 & -1
\end{pmatrix}
\]
Na Gauss-eliminatie krijgen we de rij-gereduceeerde vorm
\[ U =
\begin{pmatrix}
  1 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 1\\
  0 & 0 & 0
\end{pmatrix}
\]
Hierdoor krijgen we de oplossingsverzameling $\{(0,0,0)\}$.\\
De basis van de \underline{nulruimte} is dus $\emptyset$.\\
De rijen $r_1, r_2, r_3$ zijn niet-nulrijen, de basis van de \underline{rijruimte} is dus $vct\{(1,1,1), (1,1,-1), (1,-1,1)\}$.\\
De kolommen $c_1, c_2, c_3$ zijn onafhankelijk en voortbrengend, de basis van de \underline{kolomruimte} is dus $vct\{(1,1,1,1), (1,1,-1,-1), (1,-1,1,-1)\}$.

\subsubsection*{c)}
\[
\begin{pmatrix}
0 & 1 & -1 &  -2 & 1 \\
1 & 1 & -1 & 3   & 1 \\
2 & 1 & -1 & 8   & 3 \\
0 & 0 & -2 & 2   & 1 \\
3 & 5 & -5 & 5   & 10\\
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
1 & 0 & 0 & 5 & 0 \\
0 & 1 & 0 & -3& 0 \\
0 & 0 & 1 & -1& 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
\end{pmatrix}
\]
De eerste drie rijen van deze gereduceerde matrix vormen een basis voor de rijruimte.
De eerste drie kolommen van de gereduceerde matrix vormen een basis voor de kolomruimte. 
De oplossing van het homogeen stelsel van de gereduceerde matrix vormt de nullruimte van de matrix.
De oplossingsverzameling is de volgende.
\[
\{(-5\lambda_1,3\lambda_1,\lambda_1,\lambda_1,\lambda_2)|\lambda_1,\lambda_2\in \mathbb{R}\}
\]
We kiezen hieruit twee onafhankelijke vectoren ($2=5-3$).
\[
\left\lbrace
\begin{pmatrix}
-5\\3\\1\\1\\0\\
\end{pmatrix}
,
\begin{pmatrix}
0\\0\\0\\0\\1\\
\end{pmatrix}
\right\rbrace
\]

\subsection{oef 23}
Ik ga ervan uit dat we een bewijs moeten geven van deze stelling. Het staat er namelijk nergens bij.\\
Zij $V$ een vectorruimte met $\beta$ een basis ervan. Zij $\beta_1,...,\beta_k$ de disjuncte unie ervan. Noteer $U_i=vct(\beta_i)$.
\subsubsection*{Te Bewijzen}
\[
V = U_1 \oplus U_2 \oplus ... \oplus U_k
\]
\subsubsection*{Bewijs}
\begin{proof}
We weten dat voor elke $\beta_i,\beta_j$ de vectoren lineair onafhankelijk zijn, want samen vormen ze een basis. We weten dus al dat $\forall U_i,U_j: U_i \cap U_j = \{0\}$.\\
Nu hoeven we enkel nog te bewijzen dat $\sum_i U_i=V$. Voor elke $u_i \in U_i$ geldt dat $u_i = \sum_k\lambda_k\beta_{ik}$, in woorden: "elke $u_i$ is een lineaire combinatie van de basisvectoren van $U_i$. $\sum_i U_i$ bevat alle mogelijke lineaire combinaties van alle mogelijke $u_i$. Deze combinaties kunnen geschreven worden als lineaire combinaties van de vectoren in $\beta$. Nu hebben we dus bewezen dat $\sum_i U_i=V$ en $\forall U_i,U_j: U_i \cap U_j = \{0\}$. Hieruit volgt dat $\bigoplus_iU_i=V$.
\end{proof}



\subsection{oef 25}
Toon aan:
$ U \bigoplus W = \mathbb{R}^{n x n}$

\begin{proof}
Wat zijn de voorwaarden die moeten voldoen?
1) $ U + W = \mathbb{R}^{n x n}$
2) $ U \cap W = {0}$

nakijken 1) :
Het is duidelijk dat de doorsnede van U en W enkel de nulmatrix is.

nakijken 2) : 
De som van 2 vierkante matrices met grootte n is opniew een vierkante matrix met afmeting n. $U + W = \mathbb{R}^{n x n}$

QED

\end{proof}

\subsection*{oef 26}
We kiezen $U = vct\{(0,1,0), (0,0,1)\}$.\\ Hierdoor is $(\mathbb{R}, \mathbb{R}^3, +) = U + W$ en $U \cap W = \{0\}$.\\
Dan is $v = v_U + v_W$ en $w = w_U + w_W$ met
\[
v_U = (0,-10,-8), 
v_W = (2,12,8), 
w_U = (0,4,4), 
w_W = (0,0,0)
\]

\subsection*{oef 27}
\subsubsection*{a)}
$$\lambda_1 v_1 = \lambda_2 v_2 = 0$$
$$\lambda_1(1,0,1,1,2,3,5,8,...) + \lambda_2(0,1,1,2,3,5,8,...)=(0,0,0,0,0,...)$$
We nemen nu de eerste component van $v_1$ en $v_2$:
$$\lambda_1 \cdot 1 + \lambda_2 \cdot 0 = 0$$
$$\Rightarrow \lambda_1 = 0$$

$$\lambda_1 \cdot 0 + \lambda_2 \cdot 1 = 0$$
$$\Rightarrow \lambda_2 = 0$$
\subsubsection*{b)}
We beweren dat $v_3 = v_1 + v_2$.\\
We bewijzen dat $(v_3)_n = (v_1 + v_2)_n$ \hspace{5pt} $\forall n \in \mathbb{N}$\\
Dit tonen we aan per inductie:\\
\underline{Basisstap:} $(v_1 + v_2)_0 = (v_3)_0 \rightarrow (1 + 0) = 1$\\
\hspace*{4.5em} $(v_1 + v_2)_1 = (v_3)_1 \rightarrow (0 + 1) = 1$\\
\underline{Inductiestap:} Neem $n \geq 2$ en veronderstel dat $(v_1 + v_2)_{n-1} = (v_3)_{n-1}$ en $(v_1 + v_2)_{n-2} = (v_3)_{n-2}$.\\
\[
(v_1 + v_2)_n \overset{v_1 + v_2 \in V}{=} (v_1 + v_2)_{n-1} + (v_1 + v_2)_{n-2} \overset{inductiehypothese}{=} (v_3)_{n-1} + (v_3)_{n-2} = (v_3)_n
\]
\subsubsection*{c)}
Een basis is vrij en voortbrengend. $\beta = \{v_1,v_2\}$ is vrij (zie a).
Nu valt nog te bewijzen: "$\beta$ is voortbrengend voor $V$."
\begin{proof}
Neem een willekeurige vector $v \in V$. We tonen aan dat $v$ te schrijven valt als een lineaire combinatie van $v_1$ en $v_2$.
\[
v=(x_1,x_2,x_3,...)
\]
Waarbij geldt $\forall n \ge 1, n \in \mathbb{N}: x_{n+2}=x_{n+1}+x_n$
\[
v = \lambda_1v_1 + \lambda_2v_2
\]
\[
v = (\lambda_1,\lambda_2,\lambda_1+\lambda_2,\lambda_1+2\lambda_2,...)
\]
Elk element in $v$ voldoet dus aan de volgende recursieve formule.
\[
v_{n+2} = v_{n+1}+v_n=\lambda_1v_{1_{n+1}}+\lambda_2v_{2_{n+1}} + \lambda_1v_{1_{n}}+\lambda_2v_{2_{n}};
\]
Dit is juist volgens de definitie van vectorsom en scalaire vermenigvuldiging.
\end{proof}

\subsubsection*{d)}
$v_3 = (1,1)$

\subsection{oef 28}
\subsubsection*{b)}
Zij $V = \{(1,0,...),(0,1,0,...),(0,0,1,0,...),...)\}$.\\
\textbf{Te Bewijzen}\\
$V$ is geen basis van $\mathbb{R}^\mathbb{N}$.\\
\textbf{Bewijs}
\begin{proof}
In 28 a hebben we bewezen dat $V$ een vrij deel is van $\mathbb{R}^\mathbb{N}$. Om te bewijzen dat $V$ geen basis is van $\mathbb{R}^\mathbb{N}$ moeten we dus aantonen dat $V$ niet voortbrengend is voor $\mathbb{R}^\mathbb{N}$.
TODO <wat betekent $\mathbb{R}^\mathbb{N}$?>
\end{proof}

\subsection{oef 30}

\begin{proof}

Eerst de optelling.
De optelling is inwendig en overal bepaald zoals uit $R_{0}^{+} x R_{0}^{+} \rightarrow R_{0}^{+} $ 
De optelling is associatief.
$ (x + y) + z = x + (y+z) $
$ xy + z = x + yz$
$ xyz = xyz $

Er is een neutraal element.
$x \cdot 1 = x $

GEEN Tegengesteld element.
Het is niet mogenlijk om een uniek tegengesteld element te vinden voor elk element dat gelijk is aan 0.

Commutatief!
$xy = yx$

Alle eigenschappen voor de optelling zijn niet voldaan, dus het is geen geldige definitie.

Bij $ \bigotimes $ geldt distr1 ook al niet.

\end{proof}

\subsection{oef 32}
We berekenen alle $a$ waarvoor de vier gegeven basisvectoren lineair afhankelijk zijn.
\[
\begin{vmatrix}
4+a & 3 & 3 & 0\\
2 & a-1 & 5 & 10+a\\
0 & 0 & a+1 & 0\\
-2 & -1 & -5 & 0
\end{vmatrix}
= -(2-a)(10+a)(a+1)=0
\]
\[
\Leftrightarrow 
\left\lbrace
\begin{array}{c c}
a = 2 &\vee\\
a = -10 &\vee\\
a = -1\\
\end{array}
\right.
\]
Nu weten we dus dat als $a$ \textit{niet} \'e\'en van die waarden aanneemt, de doorsnede van $U$ en $W$, $\{\vec{0}\}$ zal zijn. Een basis van $\{\vec{0}\}$ is de lege verzameling en de dimensie ervan is $0$.
Tenslotte bepalen we nog voor de speciale gevallen van $a$ de dimensie en een basis.
\subsubsection*{$a = 2$}
\[
\left\lbrace
\begin{pmatrix}
6\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\1\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\3\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\12\\0\\0
\end{pmatrix}
\right\rbrace
\]
Als $a=2$ dan zien we dat de twee vectoren die $U$ opspannen lineair afhankelijk zijn. $U_2$ is dus \'e\'endimensionaal. Als we de eerste vector verwijderen zijn de overblijvende vectoren lineair afhankelijk. De dimensie van de somruimte is dus $3$. Bij gevolg is de dimensie van de doorsnede $0$ en de basis ervoor $\emptyset$.
\subsubsection*{$a=-10$}
\[
\left\lbrace
\begin{pmatrix}
5\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\-11\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\-5\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\0\\0\\0
\end{pmatrix}
\right\rbrace
\]
Hier is de dimensie van $W_a$ $1$. De als we de laatste vector verwijderen blijven er weer drie lineair onafhankelijke vectoren over. De dimensie vande doorsnede is weer $0$ en de basis daarvoor weer $\emptyset$.
\subsubsection*{$a=-1$}
\[
\left\lbrace
\begin{pmatrix}
3\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\-2\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\0\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\9\\0\\0
\end{pmatrix}
\right\rbrace
\]
We weten dat voor elke vector $u = \begin{pmatrix}
u_1\\u_2\\u_3\\u_4
\end{pmatrix} \in V\cap W$ geldt:
\[\exists \lambda_1,\lambda_2 :u = 
\lambda_1
\begin{pmatrix}
3\\2\\0\\-2
\end{pmatrix} + 
\lambda_2
\begin{pmatrix}
3\\-2\\0\\-1
\end{pmatrix}
\wedge
\exists \lambda_3,\lambda_4 :u = 
\lambda_3
\begin{pmatrix}
3\\5\\0\\-5
\end{pmatrix} + 
\lambda_4
\begin{pmatrix}
0\\9\\0\\0
\end{pmatrix}
\]
\[
\left\lbrace
\begin{array}{r l l}
u_1 &= 3\lambda_1+3\lambda_2 &= 3\lambda_3\\
u_2 &= 2\lambda_1-2\lambda_2 &= 5\lambda_3+9\lambda_4\\
u_3 &= 0\\
u_4 &= -2\lambda_1 -1\lambda_2 &= -5\lambda_3
\end{array}
\right.
\]
?? TODO <wat nu?!>

\section{Oefenzitting 5}
\subsection{oef 1}
\subsubsection*{1.1}
\underline{+} is de som van de functies\\
Neem $f,g,h \in \mathbb{R}^{\mathbb{R}}$ willekeurig.\\
Neem $x \in \mathbb{R}$ willekeurig dan is:
\begin{align*}
((f\underline{+}g)+h)(x) = (f\underline{+} g)(x) +h(x)\\
=(f(x)+g(x))+h(x)\\
=f(x)+(g(x)+h(x))\\
=f(x)+(g\underline{+}h)(x)\\
=(f\underline{+}(g\underline{+}h)(x))\\
\end{align*}
Dus:
\begin{align*}
(f\underline{+}g)\underline{+}h = f\underline{+}(g\underline{+}h)
\end{align*}
\subsubsection*{1.3}
Tegengesteld element:
\[
\forall v \in V:\;\exists v' \in V:\; v+v'=v'+v=0
\]
Stel $g'$ is het tegengesteld element van $g$.
Noteer het neutraal element als $\odot$.
\[
g' = (-1)\bullet g
\]
\begin{proof}
\[
g\textbf{+}g' = g\textbf{+} (-1)\bullet g
\]
We evalueren dit in een willekeurige $x \in R$:
\[ 
(g\textbf{+} (-1)\bullet g)(x) \overset{def\;1}{=} g(x) -g(x) = 0 = \odot
\]
Vanwege de commutativiteit geldt ook:
\[
g(x) -g(x) = -g(x) + g(x) = 0 = \odot
\]
\end{proof}
\subsubsection{1.4}
Stel $f:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto f(x)$ en $g:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto g(x)$, dan geldt voor iedere $x \in \mathbb{R}$ dat
\[ (\lambda \bullet (f \boldsymbol{+} g))(x) 
    = \lambda (f \boldsymbol{+} g)(x) 
    = \lambda (f(x) + g(x))
    = \lambda \cdot f(x) + \lambda \cdot g(x)
    = (\lambda \bullet f)(x) + (\lambda \bullet g)(x)
    = (\lambda \bullet f \boldsymbol{+} \lambda \bullet g)(x)\]
en dus $\lambda \bullet (f \boldsymbol{+} g) = \lambda \bullet f \boldsymbol{+} \lambda \bullet g $
\section{Bewijzen}
\subsection{Lemma 3.7}

$$v+x = w + x \Rightarrow v=w$$
Neem $v,w,x \in V$ en we nemen aan dat $v+x = w+x$\\
\begin{align*}
v = v + 0 \tag{neutraal element}\\
= v + (x - x) \tag{invers element}\\
=(v+x) -x \tag{communativiteit}\\
=(w+x) -x \tag{dit hebben we aangenomen}\\
= w +(x-x) \tag{communitativiteit}\\
= w+0 \tag{invers element}\\
=w \tag{neutraal element}
\end{align*}

\subsection{Lemma 3.8 punt 3}
\[(-\lambda)v = -(\lambda v) = \lambda(-v)\]
\[stel:w=0\]
\[(\lambda)(v+w) = \lambda(v) + \lambda(w) = \lambda(v) + \lambda(0) = \lambda(v) = (\lambda v) \]
\[\text{In punt 2 werd gesteld dat het tegengestelde element van v = -v}\]
\[Dus: -\lambda v = tegengstelde \cdot \lambda v\]
\[(-\lambda)v = -(\lambda v) = \lambda(-v) \]

\section{Opdrachten}
\subsection{3.9}
Neem aan dat $\lambda \cdot v = 0$ voor $\lambda \in \mathbb{R}$ en $v \in V$.\\
Er zijn dan twee mogelijkheden:\\
\begin{enumerate}
\item $\lambda = 0$ dan is het in orde.
\item $\lambda \neq 0$
\begin{align*}
v = 1\cdot v \tag{co\"efficient}
\\
= \frac{\lambda}{\lambda}\cdot v
\\
= \frac{1}{\lambda}(\lambda \cdot v) \tag{gemegde associativiteit}
\\
= \frac{1}{\lambda}(0) \tag{lemma 3.8.1}
\\
= 0
\end{align*}

\end{enumerate}
\subsection{3.21}
Om aan te tonen dat $U_1 + U_2$ deelruimten zijn van $V$ dan moeten we de drie eigenschappen van een deelruimte aantonen:
\begin{enumerate}
\item We moeten aantonen dat $0 \in U_1 + U_2$.\\
We weten dat $U_1$ en $U_2$ deelruimten zijn van $V$.\\
Dus $0 \in U_1$ en $0 \in U_2$ samen met het feit dat $0 = 0 + 0$ volgt dat $0 \in U_1 + U_2$.

\item We moeten aantonen $\forall x,y \in U_1 + U_2$ geldt: $x + y \in U_1 + U_2$.\\
Veronderstel dat twee willekeurige vectoren $x$ en $y \in U_1 + U_2$ bestaan.\\
Dan volgt uit de definitie van $U_1 + U_2$ dat er twee vectoren $x_1$ en $y_1 \in U_1$ en $x_2$ en $y_2 \in U_2$ bestaan zodat $x = x_1 + x_2$ en $y = y_1 + y_2$.\\
Hieruit volgt:
$$x + y = (x_1 + x_2) + (y_1 + y_2) = (x_1 + y_1) + (x_2 + y_2)$$
Omdat $x_1, y_1 \in U_1$ en $U_1$ is een deelruimte van V, $x_1 + y_1 \in U_1$.\\
Omdat $x_2, y_2 \in U_2$ en $U_2$ is een deelruimte van V, $x_2 + y_2 \in U_2$.\\
Nu hebben we aangetoond dat $x+y$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $x + y \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $y$ willekeurig waren geldt dit voor alle $x,y \in U_1 + U_2$.

\item We moeten aantonen dat $\forall x \in U_1 + U_2$ en $\forall r \in \mathbb{R}$ geldt: $rx \in U$.

Veronderstel dat een willekeurige $x \in U_1 + U_2$ en $r \in \mathbb{R}$ bestaan. Dan volgt uit de definitie van $U_1 + U_2$ dat er een $x_1 \in U_1$ en $x_2 \in U_2$ bestaan zodat $x = x_1 + x_2$.\\
Hieruit volgt:
$$rx = r(x_1+x_2) = rx_1+rx_2$$
Omdat $x_1 \in U_1$ en $U_1$ is een deelruimte van V, $rx_1 \in U_1$.\\
Omdat $x_2 \in U_2$ en $U_2$ is een deelruimte van V, $rx_2 \in U_2$.\\
Nu hebben we aangetoond dat $rx$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $rx \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $r$ willekeurig waren geldt dit voor alle $r \in \mathbb{R}$ en $x \in U_1 + U_2$.
\end{enumerate}
\subsection{3.24}

1) 
Neem \\ 
$$U_1 = \{(x,0,0)\} $$
$$U_2 =  \{ (0,y,0)\} $$
$$U_3 = \{ (x,y,0)\} $$
2) ???

\subsection{3.51}
$U+W$ is de deelruimte van $R[X]_{\le4}$ waarbij $a_3 = a_4$.
\[U+W = \{a_0 + a_1 X + a_2 X^2 +a_3 X^3 + a_4 X^4 | a_3 = a_4\}\]
Een basis van $U$ is simpelweg $\beta_U = \{1,X,X^2\}$. Een basis van $W$ is $\beta_W = \{X+X^2,X^3+X^4\}$. Een basis voor $U\cap W$ is $\beta_{U\cap W} = \{X+X^2\}$. Tenslotte is $\beta_{U+W} = \{1,X,X^2,X^3+X^4\}$ een basis van $U+W$. We verifi\"eren nu de dimensie stelling\footnote{Zie stelling 3.49 p 114.}.
\[
dim(U+W) + dim(U\cap W) = dimU+dimW
\]
\[
4 + 1 = 3+2
\]
Dit ziet er juist uit.

\subsection{3.59}


\end{document}