\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\chapter{Oefeningen Hoofdstuk 3}
\section{Oefeningen 3.6}
\subsection{Oefening 1}
\subsubsection*{a)}
distributiviteit-1 geldt niet.
\[
\lambda((x_1,x_2) + (y_1,y_2)  = \lambda(x_1+y_1-1,x_2+y_2-1) = (\lambda x_1+\lambda y_1-\lambda 1,\lambda x_2+\lambda y_2-\lambda 1)
\]
Terwijl de volgende formule ook geldt, maar deze niet gelijk zijn voor bij voorbeeld $\lambda = 2$.
\[
\lambda(x_1,x_2) + \lambda(y_1,y_2) = (\lambda x_1+\lambda y_1- 1,\lambda x_2+\lambda y_2-1)
\]
\subsubsection*{b)}
distributiviteit-2 geldt niet:\\
Scalaire vermenigvuldiging volgens de gegeven definitie:
$$
(\lambda_1 + \lambda_2)(x,y) = (x,y)
$$
Volgens distributiviteit-2:
$$
(\lambda_1 + \lambda_2)(x,y) = \lambda_1(x,y) + \lambda_2(x,y)
$$
$$
= (x,y) + (x,y)
$$
Optelling volgens de gegeven definitie:
$$
= (x+x, y+y)
$$

\subsubsection*{c)}
optelling is niet commutatief.
\[
(x_1,y_1) + (x_2,y_2) = (x_1+2x_2,y_1+2y_2)
\]
\[ \neq \]
\[
(x_2,y_2) + (x_1,y_1) = (x_2+2x_1,y_2+2y_1)
\]

\subsubsection*{d)}
Dit lijkt te kloppen.

\subsection{Oefening 2}
\subsubsection*{a)}
Deze verzameling vormt de unie van de drie vlakken rond de assen. Dit is geen deelruimte want de optelling is niet intern. Tegenvoorbeeld:
\[
(1,0,0) + (0,1,1) = (1,1,1) \not \in W_1
\]
\subsubsection*{b)}
$W_2$ is geen deelruimte van $\mathbb{R}^{3}$. Tegenvoorbeeld:
\[
x = (1,0,1) \in W_2 \text{ en } y = (0,1,1) \in W_2 \text{ maar } x + y = (1,1,2) \not \in W_2
\]

\subsubsection*{c)}
$W_3$ is geen deelruimte van $R^3$ want de lineaire combinatie is niet intern.\\
Tegenvoorbeeld: stel $\lambda = \pi$ en $v = (1,0,0) \in \mathbb{Q}$.
\[
\lambda v = \pi (1,0,0) = (\pi,0,0)
\]
$\pi$ is geen element van $\mathbb{Q}$.

\subsubsection*{d)}
$W_4$ is geen deelruimte van $\mathbb{R}^3$. Intu\"itief is dit makkelijk te zien omdat $W_4$ precies een sfeer beschrijft.\\
Tegenvoorbeeld: stel $v_1 = (1,0,0)$ en $v_2 =(1,0,0)$.
\[
v_1 + v_2 = (2,0,0) \not \in W_4
\]

\subsubsection*{e)}
$W_5$ is een deelruimte van $\mathbb{R}^{3 \times 3}$. Ze moet aan de 3 eigenschappen voldoen.
\begin{itemize}
\item De nulmatrix $O \in W_5$
\item $A,B \in W_5 \longrightarrow A+B \in W_5$
\[
\sum\limits_{i=1,j=1}^a (A+B)_{ij} = \sum\limits_{i=1,j=1}^a A_{ij} + \sum\limits_{i=1,j=1}^a B_{ij} = 0+0 = 0
\]
\item $ A \in W_5, \lambda \in \mathbb{R} \longrightarrow \lambda A \in W_5$
\[
\sum\limits_{i=1,j=1}^a (\lambda A)_{ij} = \lambda \sum\limits_{i=1,j=1}^a A_{ij} = \lambda 0 = 0
\]
\end{itemize}
\subsubsection*{f)}
$W_6$ is geen deelruimte van $\mathbb{R}^{3}$ omdat de nulmatrix $O \not \in W_6$ aangezien $\det(O) = 0$.

\subsubsection*{g)}
$W_7$ is een deelruimte van $\mathbb{R}^{3x3}$.
\begin{itemize}
\item De nulmatrix $O \in W_7$, de nulmatrix is immers ook een symmetrische matrix.
\item De som van twee symmetrische matrices is ook een symmetrische matrix.
\item Een symmetrische matrix vermenigvuldigen met een scalar geeft opnieuw een symmetrische matrix.
\end{itemize}

\subsubsection*{i)}
$W_9$ is geen deelruimte van $\mathbb{R}^{3\times 3}$. De optelling is namelijk niet intern.
\[
(0,1,0) + (1,0,0) = (1,1,0) \not \in W_9
\]

\subsubsection*{j)}
$W_{10}$ is geen deelruimte van $f:\mathbb{R}\rightarrow\mathbb{R}$.\\
Tegenvoorbeeld: we maken een functie $g \in W_{10}$ met $g : \mathbb{R}\rightarrow\mathbb{R} : x \mapsto e^x$.
\[
(g+g)(0) = g(0) + g(0) = 1+1 = 2 \Longrightarrow (g+g) \not \in W_{10}
\]

\subsubsection*{l)}
$W_{12}$ is een deelruimte van $\mathbb{R}^{3\times 3}$.\\
Het is duidelijk dat $0 \in W_{12}$.\\
Neem $f, g \in W_{12}$ en $\lambda, \mu \in \mathbb{R}$ willekeurig. Omdat $f$ en $g$ integreerbaar zijn, is $\lambda f + \mu g$ integreerbaar.
\begin{align*}
  \int^1_0 (\lambda f + \mu g)(x)dx &= \int^1_0(\lambda f(x) + \mu g(x))dx\\
  &= \int^1_0 \lambda f(x)dx + \int^1_0 \mu g(x)dx\\
  &= \lambda \int^1_0 f(x)dx + \mu \int^1_0 g(x)dx = \lambda \cdot 0 + \mu \cdot 0 = 0
\end{align*}



\subsection{Oefening 3}% deze oplossing was fout, deze versie is juist
\textit{Gegeven:}
\[
V = \left\{ (x_n)_{n \in \mathbb{N}} \ \middle|\ x_{n+2} = x_{n+1} + x_n \ ,\ \forall n \in \mathbb{N} \right\}
\]
\textit{Te bewijzen:}\\
We moeten aantonen dat $V$ een vectorruimte is. Dit kunnen we het makkelijkst doen door te bewijzen dat $V$ een deelruimte is van alle rijen.
\begin{proof}
We gaan de 3 eigenschappen van een deelruimte na.
\begin{itemize}
\item $0 \in V$
\item Zij $x = (x_n)_{n \in \mathbb{N}} \in V$ en $y = (y_n)_{n \in \mathbb{N}} \in V$. We controleren of $(x+y) \in V$.\\
Voor alle $n \in \mathbb{N}$ geldt:
\begin{align*}
(x+y)_{n+2}
&= x_{n+2} + y_{n+2} \\
&= x_{n+1} + x_n + y_{n+1} + y_n \\
&= (x_{n+1} + y_{n+1}) + (x_n + y_n) \\
&= (x+y)_{n+1} + (x+y)_{n+1}
\end{align*}
\item Zij $x = (x_n)_{n \in \mathbb{N}} \in V$ en $\lambda \in \mathbb{R}$. We controleren of $\lambda x \in V$.\\
Voor alle $n \in \mathbb{N}$ geldt:
\begin{align*}
(\lambda x)_{n+2}
&= \lambda \cdot x_{n+2} \\
&= \lambda \cdot x_{n+1} + \lambda \cdot x_n \\
&= (\lambda x)_{n+1} + (\lambda x)_n
\end{align*}
\end{itemize}
\end{proof}

\subsection{Oefening 4}% deze oplossing was fout, deze versie is juist
\underline{Associativiteit:} niet voldaan.\\
Neem $n=2$ en willekeurige $v,w \in \mathbb{R}^n$ en een willekeurige $x \in \mathbb{R}^n\backslash\{0\}$.
\begin{align*}
& (v \oplus w) \oplus x = (v-w) \oplus x = (v - w) - x = v - w - x \\
& v \oplus (w \oplus x) = v \oplus (w-x) = v - (w-x) = v - w + x
\end{align*}
\underline{Neutraal element:} niet voldaan.\\
Stel $e \in \mathbb{R}^n$ is een neutraal element: $e \oplus e = e-e = 0$.
\[
e \oplus (1,0,\ldots,0)
= (0,0,\ldots,0) - (1,0,\ldots,0) = (-1,0,\ldots,0)
\neq (1,0,\ldots,0)
\]
\underline{Tegengesteld element:} niet voldaan.\\
Niet gedefinieerd.\\\\
\underline{Commutativiteit:} niet voldaan.
\begin{align*}
&0 \oplus v
= (0,0,\ldots,0) \oplus (1,0,\ldots,0) = (-1,0,\ldots,0) \\
&v \oplus 0
= (1,0,\ldots,0) \oplus (1,0,\ldots,0) = (1,0,\ldots,0)
\end{align*}
\underline{Distributiviteit-1:} wel voldaan.\\
Zij willekeurige $v,w \in \mathbb{R}^n$ en $\lambda \in \mathbb{R}$.
\begin{align*}
\lambda \cdot (v \oplus w)
&= \lambda \cdot (v-w) = -\lambda(v-w) = -\lambda v + \lambda w \\
&= -\lambda(v \oplus w) = -\lambda(v-w) = -\lambda v + \lambda w
\end{align*}
\underline{Distributiviteit-2:} niet voldaan.
\begin{align*}
(1+1) \cdot (1,0,\ldots,0)
&= 2 \cdot (1,0,\ldots,0) = -2 (1,0,\ldots,0) = (-2,0,\ldots,0) \\
&= (-1,0,\ldots,0) \oplus (-1,0,\ldots,0) = (-1,0,\ldots,0) - (-1,0,\ldots,0) = (0,0,\ldots,0)
\end{align*}
\underline{Gemengde associativiteit:} niet voldaan.\\
Zij $v = (1,0,\ldots,0)$ en $\times$ de vermenigvuldiging tussen 2 scalars.
\begin{align*}
&(1 \times 1) \cdot v = 1 \cdot v = -v \\
&1 \cdot (1 \cdot v) = - (1 \cdot v) = -(-v) = v
\end{align*}
\underline{Co\"effici\"ent 1:} niet voldaan.\\
Zij $v = (1,0,\ldots,0)$.
\[
1 \cdot v = -v \neq v
\]

\subsection{Oefening 5}
Nee, $W$ is geen deelruimte van $R[X]_{\le n}$ als $n\ge 1$. Tegenvoorbeeld:\\
We defini\"eren $f \in W$ en $g \in W$ en tonen aan dat $(f+g) \not \in W$.
\begin{align*}
&f = x^n \\
&g = -x^n + 1 \\
&f+g = x^n - x^n + 1 = 1
\end{align*}

\subsection{Oefening 6}
\subsubsection*{Gegeven}
$U$ en $W$ zijn deelruimten van een vectorruimte $(\mathbb{R},V,+)$.
\subsubsection*{Te Bewijzen}
\[
U \cup W \text{ is een deelruimte van }V \Leftrightarrow U \subset W \vee W \subset U
\]
\subsubsection*{Bewijs}
\begin{proof} Samengesteld bewijs.\\
$\Longrightarrow$ (bewijs uit het ongerijmde)\\ %TODO dit kan simpeler en sneller
Stel dat $\neg(U \subset W \wedge W \subset U)$.\\
Dit is equivalent met $U \not\subset W \wedge W \not\subset U$.
Vanuit de definitie van deelverzameling betekent deze bewering het volgende.
\[
(\exists w': w' \in W \wedge w' \not\in U) \wedge (\exists u': u' \in U \wedge u' \not\in W) 
\]
We moeten nu tot een contradictie komen met ``$U\cup W \text{ is een deelruimte van }V$''.
$U\cup W$ is een deelruimte van $V$ betekent vanuit de definitie het volgende.
\[
\forall w, u \in Ä‰,\; \forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u + \lambda_2\cdot w \in U\cup W
\]
Aangezien deze bewering geldt voor elke $w,i \in U\cup W$, geldt ze ook voor $w'$ en $u'$.
We weten nu het volgende.
\[
\forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u' + \lambda_2\cdot w' \in U\cup W
\]
met $w' \in W \wedge w' \not\in U$ en $u' \in U \wedge u' \not\in W$.\\
Als dit geldt voor elke $\lambda_1$ en $\lambda_2$, geldt het ook voor $\lambda_1= \lambda_2 = 1$ en geldt dus het volgende.
\[
u' + w' \in U \cup W
\]
We weten dat dit niet klopt, want stel als $u' + w' \in U \cup W$ en $u' \in U$, dan $w' \in U$. Contradictie.\\\\
$\Longleftarrow$ (direct bewijs)\\
Stel $U \subset W$ (het geval waarbij $W \subset U$ is analoog).\\
Er geldt dat $U\cup W = W$. Van $W$ is gegeven dat het een deelruimte is van $V$. Hiermee is bewezen dat $U\cup W$ een deelruimte is van $V$.
\end{proof}

\subsection{Oefening 7}
Om te zien of een vector $d$ tot een deelruimte behoort opgespannen door vectoren $v_1$ en $v_2$ en $v_3$ moeten we zien of er een lineaire combinatie bestaat zodat  $$a\cdot v_1 + b\cdot v_2 + c\cdot v_3 = d$$
Dus:
$$a(2,-1,3,2) + b(-1,1,1,-3) + c(1,1,9,-5) \overset{?}{=} (3,-1,0,-1)$$
We gieten dit in een matrix:
$$
\begin{pmatrix}[ccc|c]
2 & -1 & 1 &3\\
-1 & 1 & 1 & -1\\
3 & 1 &9 & 0\\
2 & -3 &-5& -1
\end{pmatrix}
$$
Door rijreductie verkrijgen we volgende matrix:
$$
\begin{pmatrix}[ccc|c]
1&0&2&0\\
0&1&3&0\\
0&0&0&1\\
0&0&0&0
\end{pmatrix}
$$
Dit is een ongeldige matrix en dus bestaat er geen lineaire combinatie zodat de vector $d$ gevormd wordt. De vector behoort dus niet tot de deelruimte.

\subsection{Oefening 8}
We willen $p(X)$ opschrijven als lineaire combinatie van $p_1(X)$, $p_2(X)$, $p_3(X)$, dus $p(X) = \lambda_1 p_1(X) + \lambda_2 p_2(X) + \lambda_2 p_3(X)$.
Hiervoor lossen we het volgende stelsel op:
\[
\left\{
\begin{array}{l l l l l}
  -1 &= &\lambda_1 &+ 2 \lambda_2 &+ 3 \lambda_3\\
  -3 &= &2 \lambda_1 &+ 5 \lambda_2 &+ 8 \lambda_3\\
  3 &= &\lambda_1 &&- 2 \lambda_3
\end{array}
\right.
\]
Dit vullen we in in een matrix, die we hierna oplossen m.b.v. rijreductie.
\[
\begin{pmatrix}[ccc|c]
  1 & 2 & 3 & -1\\
  2 & 5 & 8 & -3\\
  1 & 0 & -2 & 3
\end{pmatrix}
\longrightarrow
\begin{pmatrix}[ccc|c]
  1 & 0 & 0 & -1\\
  0 & 1 & 0 & 3\\
  0 & 0 & 1 & -2
\end{pmatrix}
\]
We resulteren dus dat $p(X) = - p_1(X) + 3 p_2(X) - 2 p_3(X)$.

\subsection{Oefening 9}
$$f(x)+g(x)-h(x)+0\cdot \exp(x) = 0$$
$$1 - 1 + 0 = 0$$
Dit is een lineaire combinatie waarbij niet alle co\"effici\"enten nul zijn en toch de nulvector als oplossing geeft. Hierdoor is $\{f,g,h,\exp\}$ geen lineair onafhankelijke deelruimte.

\subsection{Oefening 10}
We bepalen of een verzameling vrij is op 3 verschillende manieren. In (a) gebruiken we determinanten. In (b) werken we intu\"itief. In (c) zoeken we een oplossing van een homogeen stelsel.
\subsubsection*{a)}
\[
\det
\begin{pmatrix}
1 &  2 &  1 \\
2 & -1 &  7 \\
0 &  1 & -1
\end{pmatrix}
= \det
\begin{pmatrix}
-1 &  7 \\
 1 & -1
\end{pmatrix}
- 2 \cdot \det
\begin{pmatrix}
2 &  2 \\
1 & -1
\end{pmatrix}
= -6-2 \cdot (-3) = 0
\]
Deze verzameling is niet vrij omdat $\det(A) = 0$.

\subsection*{b)}
\[
v_1+v_2 = 2 \cdot
\begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}
\text{ en }
v_1 - v_2 = -2 \cdot
\begin{pmatrix}
1 & 0 \\
0 & 0
\end{pmatrix}
\]
Dus $\begin{pmatrix}
1 & 0 \\
0 & 0
\end{pmatrix}$,
$\begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}$,
$\begin{pmatrix}
0 & 0 \\
1 & 0
\end{pmatrix}$ en
$\begin{pmatrix}
0 & 0 \\
0 & 1
\end{pmatrix}$ zitten in de verzameling. Dus $\{v_1,v_2,v_3,v_4\}$ brengt de standaardbasis voort en is dus zelf ook een basis en dus ook vrij.
\subsection*{c)}
\[
\begin{pmatrix}[ccc|c]
1 &  0 &  1 & 0 \\
2 & -1 & -1 & 0 \\
0 &  3 &  2 & 0 \\
0 &  1 & -1 & 0
\end{pmatrix}
\longrightarrow
\dots
\longrightarrow
\begin{pmatrix}[ccc|c]
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\]
Deze verzameling is vrij omdat we geen oplossing verschillend van 0 vinden.

\subsection{Oefening 11}
\textit{Gegeven.}\\
Zij $(\mathbb{R},V,+)$ een vectorruimte en $v_1,v_2,\ldots,v_n,v \in V$ zodat $v_1,v_2,\ldots,v_n$ lineair onafhankelijk zijn.\\\\
\textit{Te bewijzen.}\\
$\{v_1, v_2, \ldots, v_n, v\}$ zijn lineair afhankelijk $\Longleftrightarrow$ $v$ is een lineaire combinatie van $\{v_1,v_2,\ldots,v_n\}$.\\
\begin{proof} We bewijzen de equivalentie door ze in 2 richtingen te bewijzen.\\
$\Longrightarrow$\\
Stel $\{ v_1, v_2,\ldots, v_n, v \}$ zijn lineair afhankelijk.\\
Er bestaan dus $\lambda_1, \lambda_2,\ldots, \lambda_n, \lambda \in \mathbb{R}$ (niet allemaal 0) zodat:
\[ \lambda_1 v_1 + \lambda_2 v_2 +  \ldots + \lambda_n v_n + \lambda v = 0\]
Stel nu $\lambda = 0$. Omdat $\{v_1,v_2,\ldots,v_n\}$ lineair onafhankelijk zijn, geldt er dat $\lambda_1 = \lambda_2 = \ldots = \lambda_n = 0$. Hieruit volgt dat $\lambda_1 v_1 + \lambda_2 v_2 + \ldots + \lambda_n v_n + 0 \cdot v = 0$. Dit is een contradictie en dus geldt er dat:
\[
\lambda \neq 0
\]
Nu kunnen we makkelijk aantonen dat $v$ een lineaire combinatie is van $\{v_1,v_2,\ldots,v_n\}$:
\[
v = \frac{\lambda_1}{\lambda}v_1 - \frac{\lambda_2}{\lambda}v_2 - \ldots - \frac{\lambda_n}{\lambda}v_n
\]\\
$\Longleftarrow$\\
Stel $v$ is een lineaire combinatie van $\{v_1,\ldots,v_n\}$.\\
Er bestaan dus $\lambda_1, \lambda_2,\ldots, \lambda_n \in \mathbb{R}$ zodat:
\[
v = \lambda_1 v_1 + \lambda_2 v_2 +  \ldots + \lambda_n v_n
\]
Er geldt dan:
\[
-v + \lambda_1 v_1 + \lambda_2 v_2 +  \ldots + \lambda_n v_n = 0
\]
Dus niet alle alle $\lambda_1, \lambda_2,\ldots, \lambda_n, \lambda$ zijn gelijk aan 0 en dus is $\{v_1, v_2, \ldots, v_n, v\}$ lineair afhankelijk.
\end{proof}
 
\subsection{Oefening 12}
Voor willekeurige $\lambda_i \in \mathbb{R}$ geldt:
\begin{align*}
\lambda_1(e_1-e_2) + \lambda_2 (e_2-e_3) + \ldots + \lambda_n(e_n-e_1) &=0 \\
\lambda_1e_1 + \lambda_2e_2 + \ldots + \lambda_ne_n - \lambda_1e_2 - \lambda_2e_3 - \ldots - \lambda_ne_1 &=0 \\
(\lambda_1 - \lambda_n)e_1 + (\lambda_2 - \lambda_1)e_2 + \ldots + (\lambda_n - \lambda_{n-1})e_n &=0
\end{align*}
Dit geldt enkel als alle co\"effici\"enten nul zijn dus als $\lambda_i = \lambda_{i-1}$.\\
Dit leidt tot:
\[
\lambda_1 = \lambda_2 = \ldots = \lambda_{n-1} = \lambda_n
\]
Neem nu bijvoorbeeld $\lambda_1 = \ldots = \lambda_n = 3$, dan geldt er:
\[
3\cdot(e_1-e_2) + 3\cdot(e_2-e_3) + \ldots + 3\cdot(e_n-e_1) = 0
\]
Aangezien we een oplossing vinden waarbij niet alle $\lambda_i$ verschillend van 0 zijn, kunnen we besluiten dat de gegeven verzameling geen vrij deel is.

\subsection{Oefening 13}
Hiervoor kunnen we aantonen dat $\{1+X,1+X^2,X+X^2\}$ minimaal voortbrengend is, hiervoor laten we zien dat elke vector uit  $(\mathbb{R},\mathbb{R}[X]_{\leq 2},+)$ een lineaire combinatie is van de basisvectoren:
\[
aX^2 + bX + c = \lambda_{1} (1+X) + \lambda_{2} (1+X^2) + \lambda_{3} (X+X^2)
\]
Als we deze vergelijking uitwerken krijgen we:
\begin{align*}
a &= \lambda_2 + \lambda_3 \\
b &= \lambda_1 + \lambda_3 \\
c &= \lambda_1 + \lambda_2
\end{align*}
Dit is een stelsel met exact 1 oplossing. Hiermee tonen we aan dat het stelsel voortbrengend is en minimaal voortbrengend. Moesten we nog extra vergelijkingen er aan toevoegen zouden we redundantie invoeren of het stelsel onoplosbaar maken.
\\
\\
De co\"ordinaten van de vector $4 -3X + X^2$ kunnen we berekenen ze in een stelsel te gieten:
$$
\begin{pmatrix}[ccc|c]
1&1&0&4\\
1&0&1&-3\\
0&1&1&1
\end{pmatrix}
$$
Via rijoperaties verkrijgen we dan:
$$
\begin{pmatrix}[ccc|c]
1&0&0&0\\
0&1&0&4\\
0&0&1&-3
\end{pmatrix}
$$
Dit komt overeen met de co\"ordinaten $(0,4,-3)$.
\\
\\
De co\"ordinaten $(2,-3,1)$ komt dan weer overeen met:
$$
2\cdot (1+X) -3 \cdot (1+X^2)+ 1\cdot (X+X^2)= -1 +3X-2X^2
$$

\subsection{Oefening 14}

\subsubsection*{a)}
Beschouwen we eerst de verzameling met alleen het eerste element van de voorgestelde basis. We voegen nu stapsgewijs de daaropvolgende elementen toe, en proberen voor elk toegevoegd element dit element te schrijven als een lineaire combinatie van de reeds toegevoegden. Indien dit lukt maakt het de verzameling lineair afhankelijk en voegen we het niet toe. Indien het geen lineaire combinatie is kunnen we het toevoegen aan onze nieuwe verzameling zonder de vrijheid ervan in gevaar te brengen.\\\\
Het toevoegen van $(1,2,0)$ is triviaal. Geen veelvoud van $(1,2,3)$ kunnen we gelijk stellen hieraan. Het mag dus bij de verzameling. De volgende elementen zullen we meer systematisch aanpakken.\\\\
Bij het toevoegen van $(1,1,1)$ proberen we dit te schijven als een lineaire combinatie van de voorgaande als volgt:
\[
a \cdot (1,2,3) + b \cdot (1,2,0) = (1,1,1)
\]
Dit is equivalent met het stelsel
\[
\left\{
\begin{array}{l}
a + b = 1\\
2a + 2b = 1\\
3a = 1
\end{array} \right.
\]
wat resulteert in het strijdig (in de eerste twee regels, maar ook indien men het verder probeert uit te werken) stelsel
\[
\left\{
\begin{array}{l}
a + b = 1\\
a + b = \frac{1}{2}\\
a = \frac{1}{3}
\end{array} \right.
\]
$(1,1,1)$ is dus geen lineaire combinatie van de eerste twee, en mogen we dus aan onze vrije verzameling toevoegen, deze blijft vrij. Passen we dit stramien toe op de volgende vector, namelijk $(1,1,0)$, vinden we dat deze een lineaire combinatie is, namelijk
\[
-\frac{1}{3} \cdot (1,2,3) + \frac{1}{3} \cdot (1,2,0) + (1,1,1) = (1,1,0)
\]
Dit kunnen we makkelijk met een stelsel bekomen. We zien dus dat dit een lineaire combinatie is, en voegen het niet toe aan de verzameling. Deze is dus nog steeds $\{(1,2,3), (1,2,0), (1,1,1)\}$.\\
De laatste vector schrijven we nog even met een stelsel op voor de duidelijkheid. Indien het stelsel
\[
\left\{
\begin{array}{l}
a + b + c = 4\\
2a + 2b + c = 5\\
3a + c = 6
\end{array} \right.
\]
klopt, dan is de vector $(4,5,6)$ een lineaire combinatie van onze vrije verzameling.\\
We kunnen dit oplossen als matrix die we rijreduceren:
\[
\begin{pmatrix}[ccc|c]
1 & 1 & 1 & 4\\
2 & 2 & 1 & 5\\
3 & 0 & 1 & 6
\end{pmatrix}
\]
\[R_2 \mapsto -R_2 + 2R_1 \]
\[R_3 \mapsto -R_3 + 2R_1 \]
\[
\begin{pmatrix}[ccc|c]
1 & 1 & 1 & 4\\
0 & 0 & 1 & 3\\
0 & 3 & 2 & 6
\end{pmatrix}
\]
\[R_2 \leftrightarrow R_3\]
\[
\begin{pmatrix}[ccc|c]
1 & 1 & 1 & 4\\
0 & 3 & 2 & 6\\
0 & 0 & 1 & 3
\end{pmatrix}
\]
\[R_1 \mapsto R_1 - R_3 \]
\[R_2 \mapsto R_2 - 2R_3 \]
\[
\begin{pmatrix}[ccc|c]
1 & 1 & 0 & 1\\
0 & 3 & 0 & 0\\
0 & 0 & 1 & 3
\end{pmatrix}
\]
\[R_2 \mapsto \frac{R_2}{3}\]
\[
\begin{pmatrix}[ccc|c]
1 & 1 & 0 & 1\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 3
\end{pmatrix}
\]
\[R_1 \mapsto R_1 - R_2\]
\[
\begin{pmatrix}[ccc|c]
1 & 0 & 0 & 1\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 3
\end{pmatrix}
\]
We besluiten dus dat $(4,5,6)$ een lineaire combinatie is uit onze verzameling, namelijk
\[
(1,2,3) + 3 \cdot (1,1,1) = (4,5,6)
\]
Deze mag dus niet bij in de verzameling.\\\\
De uitgedunde verzameling is dus $\{(1,2,3), (1,2,0), (1,1,1)\}$.\\
Dit is de originele verzameling waar stapsgewijs de lineaire combinaties uitgehaald zijn, en deze is dus vrij.

\subsubsection*{b)}
We kunnen voor de verzameling via de vorige oefening bepalen dat deze vrij is, dat laten we even buiten beschouwing.\\
We willen deze verzameling voortbrengend maken. Dit betekent dat elk element van $\mathbb{R}^{2x2}$ moet kunnen geschreven worden als een combinatie van de elementen uit de verzameling.\\\\
Beschouwen we de standaardbasis $\{\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&1\\ 0&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&0\\ 1&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&0\\ 0&1
\end{smallmatrix}
\bigr)$\}, dan kunnen we stellen dat elk van deze elementen te vormen moet zijn uit onze voorgestelde basis, als lineaire combinatie. Indien dit voor alle elementen van de standaardbasis geldt is de verzameling voortbrengend, immers, we kunnen de elementen van de standaardbasis vormen en hier lineaire combinaties van maken om alle elementen uit $\mathbb{R}^{2x2}$ te schrijven.\\
Indien er een element van de standaardbasis is dat niet als lineaire combinatie geschreven kan worden mogen we dit toevoegen, het is immers niet lineair afhankelijk, de verzameling blijft dus vrij, en de verzameling brengt nu ook dat element van de standaardbasis voort.\\\\
Voor $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ kijken we of we deze kunnen vormen als lineaire combinatie via de matrix
\[
\begin{pmatrix}[ccc|c]
1 & 2 & 0 & 1\\
-1 & 1 & -3 & 0\\
2 & -1 & 5 & 0\\
3 & 4 & 4 & 0
\end{pmatrix}
\]
\[R_2 \mapsto R_2 + R_1 \]
\[R_3 \mapsto R_3 - 2*R_1 \]
\[R_4 \mapsto R_4 - 3*R_1 \]
\[
\begin{pmatrix}[ccc|c]
1 & 2 & 0 & 1\\
0 & 3 & -3 & 1\\
0 & -5 & 5 & -2\\
0 & -2 & 4 & -2
\end{pmatrix}
\]
\[R_3 \mapsto 3*R_3 + 5*R_2 \]
\[R_4 \mapsto 3*R_4 + 3*R_2 \]
\[
\begin{pmatrix}[ccc|c]
1 & 2 & 0 & 1\\
0 & 3 & -3 & 1\\
0 & 0 & 0 & -1\\
0 & 0 & -6 & -4
\end{pmatrix}
\]
Het stelsel is strijdig, dus kunnen we beslissen dat $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ geen lineaire combinatie is van onze verzameling. Deze mag er dus bij zonder dat de vrijheid van de verzameling verdwijnt.\\\\
Nu kunnen we al beslissen dat onze basis volledig is volgens Gevolg 3.34. De standaardbasis heeft namelijk 4 elementen en deze verzameling ook. Aangezien de verzameling tevens vrij is mogen we beslissen dat de verzameling $\{\bigl(
\begin{smallmatrix}
1&-1\\ 2&3
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
2&1\\ -1&4
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&-3\\ 5&4
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$\} een basis is van $\mathbb{R}^{2x2}$.\\\\
Indien $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ wel een lineaire combinatie was zouden we deze niet toegevoegd hebben, en de andere elementen van de standaardbasis ge\"evalueerd hebben. Er moet immers volgens eerder aangehaald gevolg nog precies een element toegevoegd worden aan onze verzameling om een basis te kunnen zijn.

\subsection{Oefening 15}
\[
\lambda_1 \cdot (1,-3,2) + \lambda_2 \cdot (2,-1,1) = (1,k,5)
\]
We zetten dit in matrixvorm.
\[
\begin{pmatrix}[cc|c]
 1 &  2 & 1 \\
-3 & -1 & k \\
 2 &  1 & 5
\end{pmatrix}
\longrightarrow
\begin{pmatrix}[cc|c]
1 & 0 & 3 \\
0 & 1 & -1 \\
0 & 5 & k+3
\end{pmatrix}
\]
We moeten ervoor zorgen dat het stelsel niet-strijdig is, dit gaat enkel als we $R_2$ van $R_3$ kunnen aftrekken zodat er een nulrij overblijft. Dus:
\[
-5 = k+3 \Longrightarrow k = -8
\]

\subsection{Oefening 16}
De standaardbasis is uiteraard:
\[
\beta_1 = \{ e_1 = (1,0,0,0), e_2 = (0,1,0,0), e_3 = (0,0,1,0), e_4 = (0,0,0,1) \}
\]
De nieuwe basis is gegeven als:
\[
\beta_2 = \{ f_1 = (1,1,1,1), f_2 = (0,1,1,1), f_3 = (0,0,1,1), f_4 = (0,0,0,1) \}
\]
We gooien dit in matrixvorm:
\[
\begin{pmatrix}[cccc|c]
1 &0 &0 &0 & a_1 \\
1 &1 &0 &0 & a_2 \\
1 &1 &1 &0 & a_3 \\
1 &1 &1 &1 & a_4
\end{pmatrix}
\longrightarrow
\begin{pmatrix}[cccc|c]
1 &0 &0 &0 & a_1 \\
0 &1 &0 &0 & a_2-a_1 \\
0 &0 &1 &0 & a_3-a_2-a_1 \\
0 &0 &0 &1 & a_4-a_3-a_2-a_1
\end{pmatrix}
\]
De co\"ordinaten van $v$ ten opzichte van de nieuwe basis zijn dus:
\[
(a_1, a_2-a_1, a_3-a_2-a_1, a_4-a_3-a_2-a_1)
\]

\subsection{Oefening 17}
\subsubsection*{a)}
$W_1$ vormt een vlak. We zoeken twee lineair onafhankelijke vectoren in dat vlak, die zijn dan een basis.
\[
\{(1,-2,1),(2,-2,0)\}
\]

\subsubsection*{b)}
Voor de basis te kennen lossen we eerst volgend stelsel op want hieraan moet voldaan zijn:
\[
\begin{pmatrix}[ccc|c]
1 & 2 & -1 & 0 \\
2 & 1 &  1 & 0
\end{pmatrix}
\longrightarrow
\begin{pmatrix}[ccc|c]
1 & 0 &  1 & 0 \\
0 & 1 & -1 & 0
\end{pmatrix}
\]
Hiervoor krijgen we de oplossing $x=-k$, $y= k$, $z=k$, dus van de vorm $(-k,k,k)$.\\
We krijgen dus als basis:
\[
W_2 = \{(-\lambda, \lambda, \lambda)\mid\lambda \in \mathbb{R}\}
\Longrightarrow
\beta_2 = \{ (-1,1,1) \}
\]
Het is duidelijk dat $\dim W_2 = 1$.

\subsection{Oefening 19}
\subsubsection*{a)}
\[
A =
\begin{pmatrix}
1 & 2 &  1 & 5 \\
2 & 4 & -3 & 0 \\
1 & 2 & -1 & 1
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
1 & 2 & 0 & 3 \\
0 & 0 & 1 & 2 \\
0 & 0 & 0 & 0
\end{pmatrix}
= U
\]
Dit stelsel heeft de volgende oplossingsverzameling:
\begin{align*}
V
&= \{ (-2x_2-3x_4,x_2,-2x_4,x_4) \mid x_2,x_4 \in \mathbb{R} \} \\
&= \{ x_2(-2,1,0,0) + x_4(-3,0,-2,1) \mid x_2,x_4 \in \mathbb{R} \}
\end{align*}
Hieruit volgt de basis voor de \textbf{nulruimte}: $\{ (-2,1,0,0), (-3,0,-2,1) \}$.\\
Omdat $x_1$ en $x_3$ de gebonden variabelen zijn, is de basis van de \textbf{kolomruimte} gelijk aan de kolommen $c_1$ en $c_2$ uit de oorspronkelijke matrix $A$, dus $\{(1,2,1),(1,-3,-1)\}$.\\
De rijen $r_1$ en $r_2$ zijn niet-nulrijen, de basis van de \textbf{rijruimte} is dan gelijk aan die rijen uit de oorspronkelijke matrix $A$, dus $\{(1,2,1,5),(2,4,-3,0)\}$.
\subsubsection*{b)}
\[
A =
\begin{pmatrix}
  1 & 1 & 1\\
  1 & 1 & -1\\
  1 & -1 & 1\\
  1 & -1 & -1
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
  1 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 1\\
  0 & 0 & 0
\end{pmatrix}
= U
\]
Hierdoor krijgen we de oplossingsverzameling $\{(0,0,0)\}$. De basis van de \textbf{nulruimte} is dus $\emptyset$.\\
De rijen $r_1, r_2, r_3$ zijn niet-nulrijen, de basis van de \textbf{rijruimte} is dus $\{(1,1,1), (1,1,-1), (1,-1,1)\}$.\\
De kolommen $c_1, c_2, c_3$ zijn onafhankelijk en voortbrengend, de basis van de \textbf{kolomruimte} is dus $\{(1,1,1,1), (1,1,-1,-1), (1,-1,1,-1)\}$.

\subsubsection*{c)}
\[
A =
\begin{pmatrix}
0 & 1 & -1 &  -2 & 1 \\
1 & 1 & -1 & 3   & 1 \\
2 & 1 & -1 & 8   & 3 \\
0 & 0 & -2 & 2   & 1 \\
3 & 5 & -5 & 5   & 10\\
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
1 & 0 & 0 & 5 & 0 \\
0 & 1 & 0 & -3& 0 \\
0 & 0 & 1 & -1& 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
\end{pmatrix}
= U
\]
De oplossingsverzameling is de volgende.
\[
\{ x_4(-5,3,1,1,0) + x_5(0,0,0,0,1) \mid x_4, x_5 \in \mathbb{R}\}
\]
De \textbf{nulruimte} wordt dus bepaald door $\{ (-5,3,1,1,0) , (0,0,0,0,1) \}$.\\
De eerste drie rijen van deze oorspronkelijke matrix $A$ vormen een basis voor de \textbf{rijruimte}.\\
De eerste drie kolommen van de oorspronkelijke matrix $A$ vormen een basis voor de \textbf{kolomruimte}.

\subsection{Oefening 22}
\subsubsection*{b)}
We nemen de basissen samen en reduceren tot een nieuwe basis voor $U+W$.
\[
\begin{pmatrix}
 1 &  0 &  0 &  1 \\
-1 &  1 &  0 &  0 \\
 0 & -1 &  1 &  0 \\
 0 &  0 & -1 & -1
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
1 & 0 & 0 & 1 \\
0 & 1 & 0 & 1 \\
0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0
\end{pmatrix}
\]
Een basis voor $U+W$ is dus:
\[
\left\{
\begin{pmatrix}
1 & -1 \\
0 &  0
\end{pmatrix},
\begin{pmatrix}
 0 & 1 \\
-1 & 0
\end{pmatrix},
\begin{pmatrix}
0 &  0 \\
1 & -1
\end{pmatrix}
\right\}
\]
Hieruit volgt dat $\dim(U+W) = 3$. Aangezien $\dim U = 2$ en $\dim W = 2$, geldt:
\begin{align*}
\dim(U+W) + \dim(U \cap W) &= \dim U + \dim W \\
\dim(U \cap W) &= 2+2-3 = 1
\end{align*}
Omdat $\dim(U \cap W) \neq 0$, kunnen we besluiten dat $U+W$ geen directe som is.
\subsection{Oefening 23}
Ik ga ervan uit dat we een bewijs moeten geven van deze stelling. Het staat er namelijk nergens bij.\\
Zij $V$ een vectorruimte met $\beta$ een basis ervan. Zij $\beta_1,...,\beta_k$ de disjuncte unie ervan. Noteer $U_i=vct(\beta_i)$.
\subsubsection*{Te Bewijzen}
\[
V = U_1 \oplus U_2 \oplus ... \oplus U_k
\]
\subsubsection*{Bewijs}
\begin{proof}
We weten dat voor elke $\beta_i,\beta_j$ de vectoren lineair onafhankelijk zijn, want samen vormen ze een basis. We weten dus al dat $\forall U_i,U_j: U_i \cap U_j = \{0\}$.\\
Nu hoeven we enkel nog te bewijzen dat $\sum_i U_i=V$. Voor elke $u_i \in U_i$ geldt dat $u_i = \sum_k\lambda_k\beta_{ik}$, in woorden: ``elke $u_i$ is een lineaire combinatie van de basisvectoren van $U_i$''. $\sum_i U_i$ bevat alle mogelijke lineaire combinaties van alle mogelijke $u_i$. Deze combinaties kunnen geschreven worden als lineaire combinaties van de vectoren in $\beta$. Nu hebben we dus bewezen dat $\sum_i U_i=V$ en $\forall U_i,U_j: U_i \cap U_j = \{0\}$. Hieruit volgt dat $\bigoplus_iU_i=V$.
\end{proof}


\subsection{Oefening 25}
\textit{Te bewijzen.}
\[
U \oplus W = \mathbb{R}^{n \times n}
\]

\begin{proof}
We controleren de voorwaarden van een directe som.
\begin{itemize}
\item $U \cap W = 0$

Het is duidelijk dat $U \cap W$ enkel de nulmatrix bevat.
\item $U+W = \mathbb{R}^{n \times n}$

De som van 2 vierkante matrices behorende tot $\mathbb{R}^{n \times n}$ is opnieuw een vierkante matrix behorende tot $\mathbb{R}^{n \times n}$.
\end{itemize}
\end{proof}

\subsection{Oefening 26}
We kiezen $U = \text{vct}\{(0,1,0), (0,0,1)\}$. Hierdoor is $(\mathbb{R}, \mathbb{R}^3, +) = U + W$ en $U \cap W = \{0\}$.\\
We bekomen $v = (2,2,0) = \lambda_1 (1,6,4) + \lambda_2 (0,1,0) + \lambda_3 (0,0,1)$. Na dit in een matrix te gieten en dit stelsel op te lossen bekomen we $\lambda_1 = 2$, $\lambda_2 = -10$ en $\lambda_3 = -8$. Dus:
\begin{align*}
v &= 2\cdot (1,6,4) -10\cdot (0,1,0) -8\cdot (0,0,1)
   = (2,12,8) - (0,-10,0) - (0,0,-8) \\
  &= v_U + v_W = (0,-10,-8) + (2,12,8)
\end{align*}
Op dezelfde manier berekenen we $w$ als som van een vector in $U$ en een vector in $W$.
\[
w = w_U + w_W = (0,4,4) + (0,0,0)
\]

\subsection{Oefening 27}
\subsubsection*{a)}
Stel $\lambda_1,\lambda_2 \in \mathbb{R}$ zodat:
\begin{align*}
&\lambda_1 v_1 + \lambda_2 v_2 = 0 \\
&\lambda_1(1,0,1,1,2,3,5,8,\ldots) + \lambda_2(0,1,1,2,3,5,8,\ldots) =(0,0,\ldots)
\end{align*}
We nemen nu de eerste component van $v_1$ en $v_2$:
\begin{align*}
\lambda_1 \cdot 1 + \lambda_2 \cdot 0 = 0
& \Rightarrow \lambda_1 = 0 \\
\lambda_1 \cdot 0 + \lambda_2 \cdot 1 = 0
& \Rightarrow \lambda_2 = 0
\end{align*}
Hieruit volgt dat $\lambda_1 = \lambda_2 = 0$ en dus zijn $v_1$ en $v_2$ lineair onafhankelijk.
\subsubsection*{b)}
We beweren dat $v_3 = v_1 + v_2$.\\
We bewijzen dat $(v_3)_n = (v_1 + v_2)_n$ \hspace{5pt} $\forall n \in \mathbb{N}$\\
Dit tonen we aan per inductie:\\
\underline{Basisstap:} $(v_1 + v_2)_0 = (v_3)_0 \rightarrow (1 + 0) = 1$\\
\hspace*{4.5em} $(v_1 + v_2)_1 = (v_3)_1 \rightarrow (0 + 1) = 1$\\
\underline{Inductiestap:} Neem $n \geq 2$ en veronderstel dat $(v_1 + v_2)_{n-1} = (v_3)_{n-1}$ en $(v_1 + v_2)_{n-2} = (v_3)_{n-2}$.\\
\[
(v_1 + v_2)_n \overset{v_1 + v_2 \in V}{=} (v_1 + v_2)_{n-1} + (v_1 + v_2)_{n-2} \overset{inductiehypothese}{=} (v_3)_{n-1} + (v_3)_{n-2} = (v_3)_n
\]
\subsubsection*{c)}
Een basis is vrij en voortbrengend. $\beta = \{v_1,v_2\}$ is vrij (zie a).
Nu valt nog te bewijzen: "$\beta$ is voortbrengend voor $V$."
\begin{proof}
Neem een willekeurige vector $v \in V$. We tonen aan dat $v$ te schrijven valt als een lineaire combinatie van $v_1$ en $v_2$.
\[
v=(x_1,x_2,x_3,...)
\]
Waarbij geldt $\forall n \ge 1, n \in \mathbb{N}: x_{n+2}=x_{n+1}+x_n$
\[
v = \lambda_1v_1 + \lambda_2v_2
\]
\[
v = (\lambda_1,\lambda_2,\lambda_1+\lambda_2,\lambda_1+2\lambda_2,...)
\]
Elk element in $v$ voldoet dus aan de volgende recursieve formule.
\[
v_{n+2} = v_{n+1}+v_n=\lambda_1v_{1_{n+1}}+\lambda_2v_{2_{n+1}} + \lambda_1v_{1_{n}}+\lambda_2v_{2_{n}};
\]
Dit is juist volgens de definitie van vectorsom en scalaire vermenigvuldiging.
\end{proof}
\subsubsection*{d)}
$v_3 = (1,1)$

\subsection{Oefening 28}
\textit{Gegeven.}\\
We defini\"eren  $v_i = (0,0,\ldots,0,0,1,0,0,\ldots)$ waarbij de 1 op de $i$-de plaats staat.
\[
A = \{v_1,v_2,\ldots,v_n,\ldots\}
\]

\subsubsection*{a)}
\textit{Te bewijzen.}\\
$A$ is een vrij deel van $\mathbb{R}^\mathbb{N}$.
\begin{proof}
Zij $\lambda_1,\lambda_2,\ldots,\lambda_k \in \mathbb{R}$ en $(v_i)_1,(v_i)_2,\ldots,(v_i)_k$ verschillende elementen in $A$ zodat:
\[
\lambda_1 (v_i)_1 + \lambda_2 (v_i)_2 + \ldots + \lambda_k (v_i)_k = 0
\]
Als je naar de $(i)_j$-de plaats kijkt, zie je dat $\lambda_j=0$ met $j \in \{1,2,\ldots,k\}$.\\
Hieruit volgt dus $\lambda_1 = \lambda_2 = \ldots = \lambda_k = 0$.
\end{proof}

\subsubsection*{b)}
\textit{Te bewijzen.}\\
$A$ is geen basis van $\mathbb{R}^\mathbb{N}$. Dus $A$ is niet voortbrengend.
\begin{proof}
Neem vector $x=(1,1,\ldots) \in \mathbb{R}^\mathbb{N}$, we gaan nu bewijzen dat je die vector $x$ niet kan vormen door een \textbf{eindige} som te nemen van vectoren uit $A$.\\
Neem willekeurige $f_1,f_2,\ldots,f_n \in A$, dan is er een $i \in \mathbb{N}$ zodat:
\[
v_i \not \in \{f_1,f_2,\ldots,f_n\}
\]
Dus op plaats $i$ in $x$ zal een 0 komen waardoor je $(1,1,\ldots)$ niet kan vormen.
\end{proof}

\subsection{Oefening 29}
\subsubsection*{(a)}
Niet waar. Tegenvoorbeeld.\\
In $V=(\mathbb{R},\mathbb{R},+)$ defini\"eren we $\alpha = \{1\}$ en $\beta = \{2\}$, deze zijn beide vrij in $V$.\\
Het is echter makkelijk in te zien dat hun unie $\alpha \cup \beta = \{1,2\}$ niet vrij is in $V=(\mathbb{R},\mathbb{R},+)$.

\subsubsection*{(b)}
Niet waar. Tegenvoorbeeld.\\
Kies $V = W = \mathbb{R}$ en $\alpha = \{1\}$ en $\beta = \{-1\}$.\\
Dan is $V \cap W = V = W = \mathbb{R}$ en $\alpha \cap \beta = \emptyset$ en is dus te klein om een basis te zijn in $\mathbb{R}$.

\subsubsection*{(c)}
Niet waar. Tegenvoorbeeld:\\
Kies $V= \mathbb{R}$, $v=-1$ en $w=1$ die beiden behoren tot $V$.\\
Nu geldt dat $v+w \in \{0\}$. Het is duidelijk dat $\{0\}$ een deelruimte is van $V$ maar $v \not \in \{0\}$ en $w \not \in \{0\}$.

\subsubsection*{(d)}
Waar.
\[
0 \le \dim U_1 \le \dim U_2 \le \ldots \le \dim U_r \le n
\]
Omdat $r > n+1$ moet er een $i$ bestaan zodat:
\[
\dim U_{i+1} = \dim U_i
\]
Aangezien $U_i \subset U_{i+1}$ geldt er:
\[
U_{i+1} = U_i
\]

\subsubsection*{(e)}
Waar. Voorbeeld.\\
Kies $V = \mathbb{R}[X]_{\le 2}$ en $W = \mathbb{R}[X]_{\le 1}$.
Kies $e_1,e_2,e_3$ als volgt. 
\[
e_1 = 1, e_2 = X, e_3= X^2
\]
Nu bestaat er een basis voor $V$ waarvan geen enkel element in $W$ zit, bijvoorbeeld:
\[
\left\{
X^2, X^2+1, X^2+X
\right\}
\]

\subsection{Oefening 30}
Het is makkelijk in te zien dat dit klopt als we naar logaritmes kijken.
\begin{proof}
Bewijs van een vectorruimte\footnote{Zie Definitie 3.2 en 3.3 p. 88 en 89.}.
\begin{enumerate}
\item
Optelling
\begin{itemize}
\item Intern en bepaald.\\
Ja, it staat al in ``$R_{0}^{+} x R_{0}^{+} \rightarrow R_{0}^{+}$ ''.
\item Associatief.\\
Ja, de vermenigvuldiging is associatief.
\item Neutraal Element.\\
Ja, het neutraal element is $1$.
\item Tegengesteld Element.\\
Ja, het tegengesteld element $v'$ van $v$ is gelijk aan $\frac{1}{v}$.
\item Commutatief.\\
Ja, de vermenigvuldiging is commutatief.
\end{itemize}
\item
Scalaire vermenigvuldiging
\begin{itemize}
\item Distributiviteit-1.\\
Ja, $(v\cdot w)^\lambda = v^\lambda \cdot w^\lambda$.
\item Distributiviteit-2.\\
Ja, $v^{\lambda_1 + \lambda_2} = v^{\lambda_1}\cdot v^{\lambda_2}$
\item Gemengde Associativiteit.\\
Ja, $v^{\lambda_2^{\lambda_1}} = v^{\lambda_1 \cdot \lambda_2}$
\item Co\"efficient 1.\\
Ja, $v^{1} = v$
\end{itemize}
\end{enumerate}
\end{proof}


\subsection{Oefening 31}
\subsubsection*{a)}
Neen, dit is geen deelruimte; dit is zelfs geen vectorruimte. Een simpel tegenvoorbeeld:\\

$(1,0,1)$ is een element van de verzameling, alsook $(1,0,-1)$, dit is makkelijk na te gaan door invulling. Hun som daarentegen, $(2,0,0)$ voldoet niet aan het voorschrift.\\

Hierdoor is niet voldaan aan Stelling 3.11 en is $K$ bijgevolg geen deelruimte.

\subsubsection*{b)}

De dimensie van $\mathbb{R}^3$ is 3, dit komt triviaal voort uit de standaardbasis $\{(1,0,0),(0,1,0),(0,0,1)\}$.\\

De verzameling $\{(1,0,1),(0,1,1),(0,0,1)\}$ van elementen uit $K$ is lineair onafhankelijk, dit is triviaal te bewijzen met de stelsels

\[
\left\{
\begin{array}{l}
a = 0\\
0 = 1\\
a = 1
\end{array} \right.
\]

en

\[
\left\{
\begin{array}{l}
a = 0\\
b = 0\\
a + b = 1
\end{array} \right.
\]

die we met het uitdunningsalgoritme bekomen. Beide zijn strijdig, dus is de verzameling vrij. Roepen we weer Stelling 3.11 aan, weten we dat voor $\mathbb{R}^3$ een vrije verzameling met 3 elementen een basis is. Aangezien de verzameling een basis bevat van $\mathbb{R}^3$, wordt $\mathbb{R}^3$ ook voortgebracht door $K$ zelf.

\subsection{Oefening 32}
We berekenen alle $a$ waarvoor de vier gegeven basisvectoren lineair afhankelijk zijn.
\[
\begin{vmatrix}
4+a & 3 & 3 & 0\\
2 & a-1 & 5 & 10+a\\
0 & 0 & a+1 & 0\\
-2 & -1 & -5 & 0
\end{vmatrix}
= -(2-a)(10+a)(a+1)=0
\]
\[
\Leftrightarrow 
\left\lbrace
\begin{array}{c c}
a = 2 &\vee\\
a = -10 &\vee\\
a = -1\\
\end{array}
\right.
\]
\subsubsection*{Geval 1: $a \in \mathbb{N}\backslash\{-10,-1,2\}$}
De doorsnede van $U$ en $V$ is $\{\vec{0}\}$. Een basis van $\{\vec{0}\}$ is de lege verzameling en $\dim\{\vec{0}\}=0$.

\subsubsection*{Geval 2: $a = 2$}
\begin{align*}
U_2 &= \text{vct}\{(6,2,0,-2),(3,1,0,-1)\} = \text{vct}\{(6,2,0,-2),(3,1,0,-1)\}\\
V_2 &= \text{vct}\{(3,5,3,-5),(0,12,0,0)\}
\end{align*}
De twee vectoren die $U_2$ opspannen zijn lineair afhankelijk, $U_2$ is dus \'e\'endimensionaal. Als we de eerste vector verwijderen zijn de overblijvende vectoren lineair onafhankelijk. De dimensie van de somruimte is dus $3$.
\[
U_2+V_2 = \text{vct}\{(3,1,0,-1),(3,5,3,-5),(0,12,0,0)\}
\]
Hierdoor is de dimensie van $U_2 \cap W_2$ gelijk aan 0, een basis hiervoor is dus $\emptyset$.

\subsubsection*{Geval 3: $a=-10$}
\begin{align*}
U_{-10} &= \text{vct}\{(-6,2,0,-2),(3,-11,0,-1)\} \\
V_{-10} &= \text{vct}\{(3,5,-9,-5),(0,0,0,0)\} = \text{vct}\{(3,5,-9,-5)\}
\end{align*}
Hier is de dimensie van $V_{-10}$ gelijk aan 1. Er blijven opnieuw drie lineair onafhankelijke vectoren over en dus $\dim(U_{-10}+V_{-10})=3$.
\[
U_{-10}+V_{-10} = \text{vct}\{(-6,2,0,-2),(3,-11,0,-1),(3,5,-9,-5)\}
\]
De dimensie van de doorsnede is weer $0$ en een basis hiervoor is dus $\emptyset$.
\subsubsection*{Geval 4: $a=-1$}
\begin{align*}
U_{-1} &= \text{vct}\{(3,2,0,-2),(3,-2,0,-1)\} \\
V_{-1} &= \text{vct}\{(3,5,0,-5),(0,9,0,0)\}
\end{align*}
In $U_{-1}$ en in $V_{-1}$ zijn de vectoren lineair onafhankelijk, in de somruimte echter niet. Hier volstaat het om de laatste vector uit $V_{-1}$ te verwijderen. De dimensie van de somruimte is dus 3.
\[
U_{-1}+V_{-1} = \text{vct}\{(3,2,0,-2),(3,-2,0,-1),(3,5,0,-5)\}
\]
De dimensie van de doorsnede is in dit geval $1$. Als we aan de somruimte de vector $(0,0,1,0)$ toevoegen, krijgen we 4 onafhankelijke vectoren die een basis vormen voor $\mathbb{R}^4$.
\[
U_{-1} \cap V_{-1} = \text{vct}\{(0,0,1,0)\}
\]

\subsection{Extra Oefening}
\subsubsection*{1.1}
\underline{+} is de som van de functies\\
Neem $f,g,h \in \mathbb{R}^{\mathbb{R}}$ willekeurig.\\
Neem $x \in \mathbb{R}$ willekeurig dan is:
\begin{align*}
((f\underline{+}g)+h)(x) = (f\underline{+} g)(x) +h(x)\\
=(f(x)+g(x))+h(x)\\
=f(x)+(g(x)+h(x))\\
=f(x)+(g\underline{+}h)(x)\\
=(f\underline{+}(g\underline{+}h)(x))\\
\end{align*}
Dus:
\begin{align*}
(f\underline{+}g)\underline{+}h = f\underline{+}(g\underline{+}h)
\end{align*}
\subsubsection*{1.3}
Tegengesteld element:
\[
\forall v \in V:\;\exists v' \in V:\; v+v'=v'+v=0
\]
Stel $g'$ is het tegengesteld element van $g$.
Noteer het neutraal element als $\odot$.
\[
g' = (-1)\bullet g
\]
\begin{proof}
\[
g\textbf{+}g' = g\textbf{+} (-1)\bullet g
\]
We evalueren dit in een willekeurige $x \in R$:
\[ 
(g\textbf{+} (-1)\bullet g)(x) \overset{def\;1}{=} g(x) -g(x) = 0 = \odot
\]
Vanwege de commutativiteit geldt ook:
\[
g(x) -g(x) = -g(x) + g(x) = 0 = \odot
\]
\end{proof}
\subsubsection{1.4}
Stel $f:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto f(x)$ en $g:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto g(x)$, dan geldt voor iedere $x \in \mathbb{R}$ dat
\[ (\lambda \bullet (f \boldsymbol{+} g))(x) 
    = \lambda (f \boldsymbol{+} g)(x) 
    = \lambda (f(x) + g(x))
    = \lambda \cdot f(x) + \lambda \cdot g(x)
    = (\lambda \bullet f)(x) + (\lambda \bullet g)(x)
    = (\lambda \bullet f \boldsymbol{+} \lambda \bullet g)(x)\]
en dus $\lambda \bullet (f \boldsymbol{+} g) = \lambda \bullet f \boldsymbol{+} \lambda \bullet g $


\section{Opdrachten}

\subsection{Opdracht 3.9 p 94}
\label{3.9}
Neem aan dat $\lambda \cdot v = 0$ voor $\lambda \in \mathbb{R}$ en $v \in V$.\\
Er zijn dan twee mogelijkheden:\\
\begin{enumerate}
\item $\lambda = 0$ dan is het in orde.
\item $\lambda \neq 0$
\begin{align*}
v = 1\cdot v \tag{co\"effici\"ent}
\\
= \frac{\lambda}{\lambda}\cdot v
\\
= \frac{1}{\lambda}(\lambda \cdot v) \tag{gemegde associativiteit}
\\
= \frac{1}{\lambda}(0) \tag{lemma 3.8.1}
\\
= 0
\end{align*}
\end{enumerate}


\subsection{Opdracht 3.17 p 97}
\label{3.17}
\begin{enumerate}
\item
\begin{enumerate}
\item
\[
D_1 = \{(1,0,0),(0,0,1)\}
\]

\item
\[
D_2 = \{(1,1,1)\}
\]
\end{enumerate}

\item De gepunte driedimensionale ruimte is een deelruimte van zichzelf.
Elk vlak is een deelruimte, elke rechte is een deelruimte en de triviale vectorruimte $\{\vec{0}\}$ is ook een deelruimte.

\item
\[
f_1 : \mathbb{R} \rightarrow \mathbb{R} : x \mapsto 1
\]
\[
f_2 : \mathbb{R} \rightarrow \mathbb{R} : x \mapsto x
\]
\[
f_3 : \mathbb{R} \rightarrow \mathbb{R} : x \mapsto x^2
\]
\subsubsection*{Te Bewijzen}
\[
vct\{f_1,f_2,f_3\} = \mathbb{R}[X]_{\le 2}
\]
\subsubsection*{Bewijs}
\begin{proof}
Door lineaire combinaties te nemen van $f_1$, $f_2$ en $f_3$ kunnen we heel $\mathbb{R}[X]_{\le 2}$ bekomen.
\[
vct\{f_1,f_2,f_3\} = \{ \lambda f_1+ \mu f_2 + \nu f_3| \lambda,\mu,\nu \in \mathbb{R}\}
\]
\[ = \{f\ |\ f : \mathbb{R} \rightarrow \mathbb{R} : x \mapsto (\lambda 1+ \mu x + \nu x^2) ,\ \lambda,\mu,\nu \in \mathbb{R}\}= \mathbb{R}[X]_{\le 2}
\]
\end{proof}
\end{enumerate}

\subsection{Opdracht 3.18 p 98}
\label{3.18}
Zij $(\mathbb{R},V,+)$ een vectorruimte. Zij $D$ een deelverzameling van $V$ en $U_i$ deelruimten van $V$ die $D$ omvatten.

\subsubsection*{Te Bewijzen}
\[\displaystyle
vct(D) = \bigcap_{i}U_i
\]

\subsubsection*{Bewijs}
\begin{proof}
Direct bewijs.\\
Elke deelruimte $U_i$ moet minstens elke lineaire combinatie van de vectoren in $D$ bevatten.
De kleinste deelruimte $U_i$ die $D$ omvat is precies $vct(D)$. Hiervoor geldt dan $U_i = vct(D)$.
Voor elke $U_i$ geldt dus het volgende.
\[
vct(D) \subseteq U_i 
\]
Dit houdt precies in dat $vct(D) = \displaystyle\bigcap_iU_i$ geldt.
\end{proof}


\subsection{Opdracht 3.21 p 99}
\label{3.21}
Om aan te tonen dat $U_1 + U_2$ deelruimten zijn van $V$ dan moeten we de drie eigenschappen van een deelruimte aantonen:
\begin{enumerate}
\item We moeten aantonen dat $0 \in U_1 + U_2$.\\
We weten dat $U_1$ en $U_2$ deelruimten zijn van $V$.\\
Dus $0 \in U_1$ en $0 \in U_2$ samen met het feit dat $0 = 0 + 0$ volgt dat $0 \in U_1 + U_2$.

\item We moeten aantonen $\forall x,y \in U_1 + U_2$ geldt: $x + y \in U_1 + U_2$.\\
Veronderstel dat twee willekeurige vectoren $x$ en $y \in U_1 + U_2$ bestaan.\\
Dan volgt uit de definitie van $U_1 + U_2$ dat er twee vectoren $x_1$ en $y_1 \in U_1$ en $x_2$ en $y_2 \in U_2$ bestaan zodat $x = x_1 + x_2$ en $y = y_1 + y_2$.\\
Hieruit volgt:
$$x + y = (x_1 + x_2) + (y_1 + y_2) = (x_1 + y_1) + (x_2 + y_2)$$
Omdat $x_1, y_1 \in U_1$ en $U_1$ is een deelruimte van $V$, $x_1 + y_1 \in U_1$.\\
Omdat $x_2, y_2 \in U_2$ en $U_2$ is een deelruimte van $V$, $x_2 + y_2 \in U_2$.\\
Nu hebben we aangetoond dat $x+y$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $x + y \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $y$ willekeurig waren geldt dit voor alle $x,y \in U_1 + U_2$.

\item We moeten aantonen dat $\forall x \in U_1 + U_2$ en $\forall r \in \mathbb{R}$ geldt: $rx \in U$.

Veronderstel dat een willekeurige $x \in U_1 + U_2$ en $r \in \mathbb{R}$ bestaan. Dan volgt uit de definitie van $U_1 + U_2$ dat er een $x_1 \in U_1$ en $x_2 \in U_2$ bestaan zodat $x = x_1 + x_2$.\\
Hieruit volgt:
$$rx = r(x_1+x_2) = rx_1+rx_2$$
Omdat $x_1 \in U_1$ en $U_1$ is een deelruimte van $V$, $rx_1 \in U_1$.\\
Omdat $x_2 \in U_2$ en $U_2$ is een deelruimte van $V$, $rx_2 \in U_2$.\\
Nu hebben we aangetoond dat $rx$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $rx \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $r$ willekeurig waren geldt dit voor alle $r \in \mathbb{R}$ en $x \in U_1 + U_2$.
\end{enumerate}


\subsection{Opdracht 3.24 p 100} %TODO na te kijken, (a) en (b) lijken fout
\label{3.24}
\begin{enumerate}
\item
Kies $U_i$ als volgt.
$$U_1 = \{(x,0,0)\} $$
$$U_2 =  \{ (0,y,0)\} $$
$$U_3 = \{ (x,y,0)\} $$

\item
\[
U + W = \mathbb{R}[X]_{\le 4}
\]
$U+W$ is niet de directe som van $U$ en $W$ omdat sommige vectoren op verschillende manieren geschreven kunnen worden als de som van een $u\in U$ en een $w\in W$.\\
Bijvoorbeeld:
$u_1 = x$, $u_2 = 1$, $w_1 = 1$ en $w_2 = x$.
\[
u_1 + w_1 = u_2 = w_2 = x+1 \in U+W
\]
\end{enumerate}


\subsection{Opdracht 3.29 p 103}
\label{3.29}
\begin{enumerate}
\item
We lossen hiervoor het volgende homogeen stelsel op.
\[
\left\{
\begin{array}{r r r r r}
u &+ 2x &+ 0y &+ z =& 0\\
0u &- x &- y &+ z =& 0\\
-u &+ 0x &+ y &+z =& 0\\
u &+ x &+ y &+ e =& 0\\
\end{array}
\right.
\rightarrow
A=
\begin{pmatrix}
1 & 2 & 0 & 1\\
0 & -1 & -1 & 1\\
-1 & 0 & 1 & 1\\
1 & 1 & 1 & 1
\end{pmatrix}
\]
Berekenen we van deze matrix de determinant (om te zien of het homogene stelsel niet-triviale oplossingen heeft) dan vinden we $\det(A) = 7\neq 0$.
Dit houdt in dat de gegeven vectoren lineair afhankelijk zijn.

\item
Geen enkele $X^i$ kan geschreven worden als een lineaire combinatie van $X^j$ als $i\neq j$.
\end{enumerate}

%\subsection{Opdracht 3.48}
%\label{3.48}
%\begin{enumerate}
%\item


%\item


%\item


%\item


%\end{enumerate}


\subsection{Opdracht 3.51 p 115}
\label{3.51}
$U+W$ is de deelruimte van $R[X]_{\le4}$ waarbij $a_3 = a_4$.
\[U+W = \{a_0 + a_1 X + a_2 X^2 +a_3 X^3 + a_4 X^4 | a_3 = a_4\}\]
Een basis van $U$ is simpelweg $\beta_U = \{1,X,X^2\}$. Een basis van $W$ is $\beta_W = \{X+X^2,X^3+X^4\}$. Een basis voor $U\cap W$ is $\beta_{U\cap W} = \{X+X^2\}$. Tenslotte is $\beta_{U+W} = \{1,X,X^2,X^3+X^4\}$ een basis van $U+W$. We verifi\"eren nu de dimensie stelling\footnote{Zie stelling 3.49 p 114.}.
\[
\dim(U+W) + \dim(U \cap W) = \dim U+\dim W
\]
\[
4 + 1 = 3+2
\]
Dit ziet er juist uit.


%\subsection{Opdracht 3.55 p 116}
%\label{3.55}
%TODO
%\begin{enumerate}
%\item
%TODO
%
%\item
%TODO

%\end{enumerate}


\subsection{Opdracht 3.59 p 118}
\label{3.59}
\subsubsection*{Te Bewijzen}
\[
\left\lbrace
\begin{array}{c c}
a_1x_1 + b_1x_2 + c_1x_3 + d_1x_4 &= 0 \\
a_1x_1 + b_2x_2+ c_2x_3 + d_2x_4 &= 0 \\
a_1x_1 + b_3x_2+ c_3x_3 + d_3x_4 &= 0 \\
\end{array}
\right.
\]
Het bovenstaande stelsel heeft een niet-triviale oplossing (oneindig veel niet-triviale oplossingen zelfs).

\subsubsection*{Bewijs}
\begin{proof}
Het originele stelsel ziet er als volgt uit in matrixvorm.
\[
\begin{pmatrix}
a_1 & b_1 & c_1 & d_1\\
a_2 & b_2 & c_5 & d_2\\
a_3 & b_3 & c_3 & d_3\\
\end{pmatrix}
\cdot
\begin{pmatrix}
x_1\\ x_2\\x_3
\end{pmatrix}
= \vec{0}
= 
\begin{pmatrix}
a & b & c & d
\end{pmatrix}
\cdot
\begin{pmatrix}
x_1\\ x_2\\x_3
\end{pmatrix}
\]
Beschouwen we vectoren $(a_1,a_2,a_3)$, $(b_1,b_2,b_3)$, $(c_1,c_2,c_3)$ en $(d_1,d_2,d_3)$. Volgens het Lemma van Steinitz\footnote{Zie Stelling 3.32 p 104} is elke verzameling van vectoren in $\mathbb{R}^3$ met meer dan drie elementen lineaire afhankelijk. Dit geldt dus ook voor onze vier beschouwde vectoren. Als we nu stellen dat minstens \'e\'en van de vectoren samengesteld wordt uit de anderen, dan kunnen we onze onbekenden $x_1$, $x_2$, $x_3$ en $x_4$ zo kiezen dat we het tegengestelde van de samengestelde (lineair afhankelijke) vector(en) vormen uit het lineair onafhankelijk en (eventueel deels) voortbrengend deel. Stel dat $d$ lineair afhankelijk is van $a, b$ en $c$ (welke vector dit is maakt niet uit omwille van de commutativiteit van de optelling in $\mathbb{R}$.), dan ziet dit er uit als volgt.
\[
\left\lbrace
\begin{array}{c c}
-d_1x_4 + d_1x_4 &= 0 \\
-d_2x_4 + d_2x_4 &= 0 \\
-d_3x_4 + d_3x_4 &= 0 \\
\end{array}
\right.
\]
Dan is voldaan aan ons homogeen stelsel omdat beide elkaar zullen opheffen. Deze oplossing van het homogeen stelsel is niet triviaal omdat een eigenschap van lineaire onafhankelijkheid\footnote{Zie Propositie 2.26 p 101} zegt dat de co\"effici\"enten $x_1,x_2,x_3$ niet nul mogen zijn.
Deze redenering geldt voor elke keuze van $x_4\in \mathbb{R}$, dus er zijn oneindig veel triviale oplossingen.
\end{proof}


%\subsection{Opdracht 3.64 p 123}
%\label{3.64}
%TODO


\end{document}