\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}


\part{Hoofdstuk 2}
\section{Bewijzen uit het boek}
\subsection{Stelling 2.2 p 57}
Zij $f : \mathbb{R}^{n\times n} \rightarrow \mathbb{R}:A\mapsto f(A)$ een afbeeldingen die aan definitie 2.1 op pagina 57 voldoet.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item $f$ is lineair in de $i$de rij voor elke $i\in \{1,2,...,n\}$
\[
f\left(
\begin{pmatrix}
R_1 \\ \vdots \\ \lambda R_i + \mu R_i' \\ \vdots \\R_n
\end{pmatrix}
\right)
=
\lambda
f\left(
\begin{pmatrix}
R_1 \\ \vdots \\ R_i\\\vdots \\R_n
\end{pmatrix}
\right)
+
\mu 
f
\left(
\begin{pmatrix}
R_1 \\ \vdots \\ R_i' \\\vdots \\R_n
\end{pmatrix}
\right)
\] 
\item Als er in $A$ een nulrij is, of als er twee gelijke rijen zijn, dan geldt $f(A)=0$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}
\item We verwisselen rij $1$ met rij $i$ om de volgende uitdrukking te bekomen.
\[
f\left(
\begin{pmatrix}
R_1 \\ \vdots \\ \lambda R_i + \mu R_i' \\ \vdots \\R_n
\end{pmatrix}
\right)
=
-
f\left(
\begin{pmatrix}
\lambda R_i + \mu R_i' \\ \vdots \\ R_1 \\ \vdots \\R_n
\end{pmatrix}
\right)
\] 
We weten dat lineariteit geldt voor de eerste rij\footnote{Zie D-3 in Definitie 2.1 p 57}.
\[
-
f\left(
\begin{pmatrix}
\lambda R_i + \mu R_i' \\ \vdots \\ R_1 \\ \vdots \\R_n
\end{pmatrix}
\right)
=
-
\lambda
f\left(
\begin{pmatrix}
R_i \\ \vdots \\ R_1\\\vdots \\R_n
\end{pmatrix}
\right)
-
\mu 
f
\left(
\begin{pmatrix}
R_i' \\ \vdots \\ R_1 \\\vdots \\R_n
\end{pmatrix}
\right)
\] 
We verwisselen in de matrixen in beide termen opnieuw rij $1$ met rij $i$.
\[
\lambda
f\left(
\begin{pmatrix}
R_1 \\ \vdots \\ R_i\\\vdots \\R_n
\end{pmatrix}
\right)
+
\mu 
f
\left(
\begin{pmatrix}
R_1 \\ \vdots \\ R_i' \\\vdots \\R_n
\end{pmatrix}
\right)
\] 
\item
Gevalsonderscheid\\
Geval 1: $A$ heeft twee gelijke rijen.\\
Stel $R_i = R_j$ zijn gelijke rijen. We kunnen nu $R_i$ en $R_j$ omwisselen om $A'$ te bekomen. Nu zal $f(A)$ het tegengestelde zijn van $f(A')$ maar $A$ en $A'$ zijn gelijk omdat de verwisselde rijen gelijk zijn.
\[
f(A) = - f(A) \Leftrightarrow f(A)=0
\]
Geval 2: $A$ heeft een nulrij.\\
Stel dat $R_i$ een nulrij is in $A$. Vervang nu $R_i$ door $R_i'  = \lambda R_i$ (met $\lambda \neq 0$) om $A'$ te bekomen. $A$ is gelijk aan $A'$ want $\forall \lambda \in \mathbb{R}: \lambda*0=0$. Bovendien geldt door lineariteit van de $i$ de rij (zie hierboven) het volgende.
\[
f(A) = \lambda f(A')
\]
Dit kan enkel als $f(A) = 0$.
\end{enumerate}
\end{proof}

\subsection{Stelling 2.3 p 58}
Zij $f : \mathbb{R}^{n\times n} \rightarrow \mathbb{R}:A\mapsto f(A)$ een afbeeldingen die aan definitie 2.1 (determinant afbeelding) op pagina 57 voldoet.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item Als men op de matrix $A$ een elementaire rijoperatie uitvoert van het type $R_i\rightarrow R_i + \lambda R_j$ met $j\neq i$, dan verandert $f(A)$ niet.
\item Als $E$ een elementaire matrix is, dan is 
\[
\left\lbrace
\begin{array}{c l l}
f(E_1) &= 1 & \text{ als } E_1 \text{ correspondeert met } R_i \rightarrow R_i + \lambda R_j\\
f(E_2) &= -1 & \text{ als } E_2 \text{ correspondeert met } R_i \leftrightarrow R_j\\
f(E_3) &= \lambda & \text{ als } E_2 \text{ correspondeert met } R_i \rightarrow \lambda R_i\\
\end{array}
\right.
\]
\item Als $E$ een elementaire matrix is, geldt steeds dat $f(E\cdot A) = f(E)\cdot f(A)$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}
\item We weten dat de afbeelding $f$ lineair is in de $i$-de rij\footnote{Zie Stelling 2.2 p 57 D-4} dus het volgende geldt.
\[
f
\left(
\begin{pmatrix}
R_1\\ \vdots\\R_i+\lambda R_j\\\vdots\\R_j\\\vdots\\R_n
\end{pmatrix}
\right)
=
f
\left(
\begin{pmatrix}
R_1\\ \vdots\\R_i\\\vdots\\R_j\\\vdots\\R_n
\end{pmatrix}
\right)
+
\lambda
f
\left(
\begin{pmatrix}
R_1\\ \vdots\\R_j\\\vdots\\R_j\\\vdots\\R_n
\end{pmatrix}
\right)
=
f(A)
\]
De laatste gelijkheid geldt omdat de matrix in de tweede term van het middelste lid twee gelijke rijen heeft, namelijk $R_i$ en $R_j$\footnote{Zie Stelling 2.2 p 57 D-5}.

\item
Kijk even terug naar pagina 36 om te zien hoe elementaire matrices er uitzien. Onthoud bovendien dat $f(\mathbb{I}_n)=1$ \footnote{Zie definitie 2.1 p 57 D-1}.
\begin{enumerate}
\item $E_1$ bekomen we door op $\mathbb{I}_n$ de elementaire rijoperatie uit te voeren van het type $R_i\rightarrow R_i + \lambda R_j$. In Het eerste deel van dit bewijs dat deze rijoperatie niets aan de waarde van $f$ verandert dus $f(E_1) = f(\mathbb{I}) = 1$.
\item $E_2$ bekomen we door in $\mathbb{I}_n$ twee rijen van plaats te veranderen. Wanneer we twee rijen van plaats veranderen keert het teken van $f$ om dus $f(E_2) = -f(\mathbb{I}_n) = -1$.\footnote{Zie Definitie 2.1 p 57 D-2}\\\\
\item 1$E_3$ bekomen we door in $\mathbb{I}_n$ rij $R_i$ te vervangen door $R_i' = \lambda R_i$. Uit de lineariteit van $f$ volgt dat $f(E_3) = \lambda f(\mathbb{I}_n) = \lambda$\footnote{Zie Stelling 2.2 p 57 D-4}.
\end{enumerate}

\item
We moeten een gevalsonderscheid maken.
\begin{enumerate}
\item $E$ correspondeert met  $R_i \rightarrow R_i + \lambda R_j$.\\
$A' = E\cdot A$ is de matrix waarin $E$ uitgevoerd is op $A$. In het eerste deel van dit bewijs hebben we aangetoond dat de waarde van $f$ gelijk blijft als we $E$ uitvoeren op $A$. Bovendien weten we dat $f(E)=1$ uit deel twee van dit bewijs.
\[
f(E\cdot A) = f(A') = f(A) = f(E)\cdot f(A)
\]
\item $E$ correspondeert met  $R_i \leftrightarrow R_j$.\\
$A' = E\cdot A$ is de matrix waarin twee rijen verwisselt zijn zoals beschreven door $E$. Als we twee rijen verwisselen in een matrix keert het teken van $f$ om\footnote{Zie definitie 2.1 p 57 D-2}.
\[
f(E\cdot A) = f(A') = -f(A) = f(E)\cdot f(A)
\]
De bovenstaande bewering geldt want $f(E) = -1$ zoals bewezen in deel twee van dit bewijs.
\item $E$ correspondeert met $R_i \rightarrow \lambda R_i$.
$A' = E\cdot A$ is de matrix waarin rij $R_i$ vervangen is door $R_i' = \lambda R_i$. Door lineariteit in de $i$-de rij geldt dan de volgende bewering\footnote{Zie Stelling 2.2 p 57 D-4}.
\[
f(A') = \lambda f(A)
\]
\end{enumerate}
\end{enumerate}
\end{proof}

\subsection{Stelling 2.4 p 59}
Zij $f : \mathbb{R}^{n\times n} \rightarrow \mathbb{R}:A\mapsto f(A)$ een afbeeldingen die aan definitie 2.1 (determinant afbeelding) op pagina 57 voldoet.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item Als $A$ een driehoeksmatrix is, dan is $f(A)$ gelijk aan het product van de diagonaalelementen in $A$.
\[
f(A) = \prod_{i=1}^n (A)_{ii}
\]
\item $A$ is inverteerbaar $\Leftrightarrow f(A) \neq 0$.
\item $\forall A,B \in \mathbb{R}^{n\times n}: f(A\cdot B) = f(A)\cdot f(B)$
\item $f(A^T) = f(A)$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{enumerate}
\item Als $A$ een driehoeksmatrix is, is $A$ rij-equivalent (uitsluitend via rijoperaties van het type $R_i \rightarrow R_i + \lambda R_j$) met $A'$ zijnde de diagonaalmatrix met precies dezelfde elementen op de diagonaal als $A$.
\[
f(A) = f(A') = \prod_{i=1}^n (A)_{ii}
\]
De bovenstaande bewering volgt uit de lineariteit van de determinant afbeelding en uit de definitie waarin staat dat $f(\mathbb{I}_n)=1$\footnote{Zie Stelling 2.2 p 57 D-4} \footnote{Zie definitie 2.1 p 57 D-2}. $A'$ is namelijk gelijk aan de eenheidsmatrix waar herhaaldelijk de elementaire rijoperatie van type $R_i \rightarrow \lambda R_i$ op is uitgevoerd.
\item Elke inverteerbare matrix valt te bekomen door op de eenheidsmatrix $\mathbb{I}_n$ elementaire rijoperaties uit te voeren zonder ooit een rij te vervangen door een nulrij. Dit houdt in dat elke inverteerbare matrix $A$ geschreven kan worden als volgt.
\[
A = E_1\cdot ... \cdot E_k
\]
Nemen we nu van beide leden de determinant dan krijgen we de volgende uitdrukking.
\[
f(A) = f(E_1\cdot ... \cdot E_k) = f(E_1)\cdot ... \cdot f(E_k) \neq 0
\]
De tweede gelijkheid omdat $\forall A\in \mathbb{R}^{n\times n}: f(E\cdot A) = f(E)\cdot f(A)$\footnote{Zie stelling 2.3 p 58}. De derde gelijkheid geldt omdat geen enkele elementaire matrix een determinant heeft die nul is.\\\\
$A$ is altijd rij-equivalent aan een matrix $U$ in trapvorm\footnote{Zie Propositie 1.8 p 21}. Dit betekent dat er een aantal elementaire matrices $E_1',...,E_k'$ bestaan zodat de volgende bewering geldt.
\[
E_k'\cdot ...\cdot E_1' \cdot A = U
\]
Als $A$ niet inverteerbaar is zal $U$ dat ook niet zijn. Dit zou betekenen dat er op de diagonaal van $U$ een nul staat en volgens deel \'e\'en van dit bewijs is $f(A)$ dan gelijk aan nul.
\item
Als $A$ niet inverteerbaar is, dan is ook $A\cdot B$ niet inverteerbaar. Dan geldt de bewering want volgend deel twee van dit bewijs is $f(A)$ dan gelijk aan nul en $f(A)\cdot f(B) = 0\cdot f(B) = 0$ geldt.\\
Als $A$ wel inverteerbaar is is $A$ het product van elementaire matrices\footnote{Zie stelling 1.36 p 38}.
\[
A = E_1\cdot ...\cdot E_k
\]
Bijgevolg geldt de volgende bewering.
\[
f(A\cdot B) = f(E_1\cdot ...\cdot E_k \cdot B) = f(E_1\cdot ...\cdot E_k) \cdot f(B)) = f(A)\cdot f(B)
\]
De tweede gelijkheid volgt uit het feit dat $\forall A\in \mathbb{R}^{n\times n}: f(E\cdot A) = f(E)\cdot f(A)$ geldt\footnote{Zie stelling 2.3 p 58}.
\item 
Als $A$ inverteerbaar is dan is $A^T$ ook inverteerbaar en omgekeerd\footnote{Zie Opdracht 1.33 p 35}. Als $A$ niet inverteerbaar is geldt $f(A) = f(A^T)=0$. Als $A$ wel inverteerbaar is, is $A$ een product van elementaire matrices\footnote{Zie stelling 1.36 p 38}.
\[
A = E_1\cdot ...\cdot E_k \Leftrightarrow A^T =  E_k^T\cdot ...\cdot E_1^T
\]
Bovenstaande bewering geldt vanwege een eigenschap van de getransponeerde matrix van het product van matrices\footnote{Zie Eigenschap 1.22 p 32 (bovenaan)}. $f(E^T)=f(E)$ want $E$ is ofwel symmetrisch (dan is $E^T$ gelijk aan $E$) ofwel is $f(E)$ gelijk aan  $1$. De volgende bewering geldt dan dus ook.
\[
f(A) = f(E_1\cdot ...\cdot E_k) = f(E_1)\cdot ...\cdot f(E_k) = f(E_1^T)\cdot ...\cdot f(E_k^T) = f(E_k^T\cdot ...\cdot E_1^T) = f(A^T)
\]
\end{enumerate}

\section{2.4}
\subsection{oef 1}
\subsubsection*{a}
\[
\begin{vmatrix}
3 & 5\\
-2 & 4
\end{vmatrix}
= 22
\]
\subsubsection*{b)}
\[
\begin{vmatrix}
5 & 6\\
7 & 2
\end{vmatrix}
= -32
\]
\subsubsection*{c)}
\[
    \frac{1}{52} \begin{vmatrix}
        -2 & -6\\
        7 & -5
    \end{vmatrix} 
    = \frac{1}{52} \cdot 52 = 1
\]
\subsubsection*{d)}
\[
\begin{vmatrix}
1 & 5 & 0\\
2 & 4 & -1\\
0 & -2 & 0
\end{vmatrix}
= -2
\]
\subsubsection*{e)}
Door rijoperaties:
$$
\begin{vmatrix}
2 & 1 & 3\\
-1 & 2 & 0\\
1 & 8 & 6
\end{vmatrix}
=
\overset{R1 \leftrightarrow R3}{=}
\begin{vmatrix}
1 & 8 & 6\\
-1 & 2 & 0\\
2 & 1 & 3
\end{vmatrix}
\overset{R3 \longmapsto R3 + R1}{=}
\begin{vmatrix}
1 & 8 & 6\\
0 & 10 & 6\\
2 & 1 & 3
\end{vmatrix}
\overset{R3 \longmapsto R3 - 2\cdot R1}{=}
\begin{vmatrix}
1 & 8 & 6\\
0 & 10 & 6\\
0 & -15 & -9
\end{vmatrix}
= 0
$$
Merk op: $R3 = -\frac{3}{2} R2$ vandaar $0$.\\
\\
Door ontwikkeling:
$$
\begin{vmatrix}
2 & 1 & 3\\
-1 & 2 & 0\\
1 & 8 & 6
\end{vmatrix}
=
3 \cdot
\begin{vmatrix}
-1 & 2\\
1 & 8
\end{vmatrix}
-0
+6 \cdot
\begin{vmatrix}
2 & 1\\
-1 & 2
\end{vmatrix}
= 0
$$
\subsubsection*{f)}
Door rijoperaties:
$$
\begin{vmatrix}
1 & 1 & 3\\
2 & 3 & 4\\
1 & 5 & 7
\end{vmatrix}
\overset{R2 \longmapsto R2-2R1}{=}
\begin{vmatrix}
1 & 1 & 3\\
0 & 1 & -2\\
1 & 5 & 7
\end{vmatrix}
\overset{R3 \longmapsto R3-R1}{=}
\begin{vmatrix}
1 & 1 & 3\\
0 & 1 & -2\\
0 & 4 & 4
\end{vmatrix}
\overset{R3 \longmapsto R3-4R2}{=}
\begin{vmatrix}
1 & 1 & 3\\
0 & 1 & -2\\
0 & 0 & 12
\end{vmatrix}
$$
$$ = 1\cdot 1 \cdot 12 = 12$$
Door ontwikkeling:
$$
\begin{vmatrix}
1 & 1 & 3\\
2 & 3 & 4\\
1 & 5 & 7
\end{vmatrix}
= 1 \cdot
\begin{vmatrix}
3 & 4\\
5 & 7
\end{vmatrix}
- 1 \cdot 
\begin{vmatrix}
2 & 4\\
1 & 7
\end{vmatrix}
+3\cdot
\begin{vmatrix}
2 & 3\\
1 & 5
\end{vmatrix}
$$
$$
= 1 - 10 + 3\cdot 7 = 12
$$
\subsubsection*{g)}
1)
\[
\begin{pmatrix}
0 & 1 & 1 & 1\\
2 & 0 & 1 & 1\\
2 & 2 & 0 & 1\\
1 & 1 & 1 & 0
\end{pmatrix}
\]
\[R1 \leftrightarrow R4\]
\[R2 \leftrightarrow R3\]
\[
\begin{pmatrix}
1 & 1 & 1 & 0\\
2 & 2 & 0 & 1\\
2 & 0 & 1 & 1\\
0 & 1 & 1 & 1
\end{pmatrix}
\]
\[R2 \longmapsto R2- 2 \cdot R1 \]
\[R3 \longmapsto R3- 2 \cdot R1 \]
\[
\begin{pmatrix}
1 & 1 & 1 & 0\\
0 & 0 & -2 & 1\\
0 & -2 & -1 & 1\\
0 & 1 & 1 & 1
\end{pmatrix}
\]
\[R4 \leftrightarrow R2\]
\[R3 \longmapsto R3 + 2 \cdot R2\]
\[
\begin{pmatrix}
1 & 1 & 1 & 0\\
0 & 1 & 1 & 1\\
0 & 0 & 1 & 3\\
0 & 0 & -2 & 1
\end{pmatrix}
\]
\[R4 \longmapsto R4 + 2 \cdot R3\]
\[
\begin{pmatrix}
1 & 1 & 1 & 0\\
0 & 1 & 1 & 1\\
0 & 0 & 1 & 3\\
0 & 0 & 0 & 7
\end{pmatrix}
\]
\[det = -7 \text{(3 rijwissels)} \]
2)
\[ -2 \cdot det
\begin{pmatrix}
1 & 1 & 1\\
2 & 0 & 1\\
1 & 1 & 0
\end{pmatrix}
+2 \cdot det
\begin{pmatrix}
1 & 1 & 1\\
0 & 1 & 1\\
1 & 1 & 0
\end{pmatrix}
- det 
\begin{pmatrix}
1 & 1 & 1\\
0 & 1 & 1\\
2 & 0 & 1
\end{pmatrix}
=-7
\]
\subsubsection*{h)}
\[ det
\begin{pmatrix}
4 & 3 & 1 & 5\\
4 & 0 & -2 & 4\\
8 & 9 & 5 & -11\\
8 & 3 & -1 & 9
\end{pmatrix}
\]
\[ = -3 \cdot det
\begin{pmatrix}
4 & -2 & 4\\
8 & 5 & -11\\
8 & -1 & 9
\end{pmatrix}
-9 \cdot det 
\begin{pmatrix}
4 & 1 & 5\\
4 & -2 & 4\\
8 & -1 & 9
\end{pmatrix}
+3 \cdot det
\begin{pmatrix}
4 & 1 & 5\\
4 & -2 & 4\\
8 & 5 & -11
\end{pmatrix}
= 0
\]

\subsubsection*{i)}
\[
\begin{vmatrix}
5 & 0 & 3 & 2 & 0\\
0 & 0 & 0 & 0 & 4\\
0 & 0 & -3  & 1 & 0\\
0 & 0 & 0 & 1 & 1\\
0 & -2 & 4 &0  &8
\end{vmatrix}
\]
Wissel R2 en R5
\[
=-
\begin{vmatrix}
5 & 0 & 3 & 2 & 0\\
0 & -2 & 4 &0  &8\\
0 & 0 & -3  & 1 & 0\\
0 & 0 & 0 & 1 & 1\\
0 & 0 & 0 & 0 & 4
\end{vmatrix}
= - (5 \cdot -2 \cdot -3 \cdot 1 \cdot 4) = -120
\]

\subsubsection*{j)}
Door rijoperaties:\\
\[
\begin{vmatrix}
3 & -7 & 8 & 9 & -6\\
0 & 2 & -5 & 7 & 3\\
0 & 0 & 1 & 5 & 0\\
0 & 0 & 2 & 4 & -1\\
0 & 0 & 0 & -2 & 0
\end{vmatrix}
\overset{R4 \longmapsto R4-2R3}{=}
\begin{vmatrix}
3 & -7 & 8 & 9 & -6\\
0 & 2 & -5 & 7 & 3\\
0 & 0 & 1 & 5 & 0\\
0 & 0 & 0 & -6 & -1\\
0 & 0 & 0 & -2 & 0
\end{vmatrix}
\]
\[
\overset{R5 \longmapsto R5-\frac{-2}{6}R4}{=}
\begin{vmatrix}
3 & -7 & 8 & 9 & -6\\
0 & 2 & -5 & 7 & 3\\
0 & 0 & 1 & 5 & 0\\
0 & 0 & 0 & -6 & -1\\
0 & 0 & 0 & 0 & \frac{-2}{6}
\end{vmatrix}
=
3\cdot 2 \cdot 1 \cdot (-6) \cdot (-\frac{2}{6}) = 12
\]\\
Door ontwikkeling:
\[
\begin{vmatrix}
3 & -7 & 8 & 9 & -6\\
0 & 2 & -5 & 7 & 3\\
0 & 0 & 1 & 5 & 0\\
0 & 0 & 2 & 4 & -1\\
0 & 0 & 0 & -2 & 0
\end{vmatrix}
=
3 \cdot
\begin{vmatrix}
2 & -5 & 7 & 3\\
0 & 1 & 5 & 0\\
0 & 2 & 4 & -1\\
0 & 0 & -2 & 0
\end{vmatrix}
=
3 \cdot 2 \cdot
\begin{vmatrix}
1 & 5 & 0\\
2 & 4 & -1\\
0 & -2 & 0
\end{vmatrix}
\]
\[
3\cdot 2\cdot \left( 
\begin{vmatrix}
4 & -1\\
-2 & 0
\end{vmatrix}
-2\cdot
\begin{vmatrix}
5 & 0\\
-2 & 0
\end{vmatrix}
\right)
=
3\cdot 2 \cdot 2 = 12
\]

\subsection{oef 2}
\[det(A) = -7, det(B) = 3\]
\begin{gather*}
    det(A^2BA^{-1}) =
    det(A^2) \cdot det(B) \cdot det(A^{-1}) =\\
    det(A)^2 \cdot det(B) \cdot det(A)^{-1} = det(A) \cdot det(B) = -21
\end{gather*}
\begin{gather*}
    det(B^{-1}A^3) = det(B^{-1}) \cdot det(A^3) = det(B)^{-1} \cdot det(A)^3 = \frac{1}{3} \cdot (-7)^3 = \frac{-343}{3}
\end{gather*}

\subsection{oef 3}
$det(AB) = 0$ als $det(A) = 0$ of $det(B) = 0$
\\
\[det(A) = \begin{vmatrix}
x + 2 & 3x\\
3 & x + 2
\end{vmatrix}
 = (x + 2)^2 - 9x = x^2 -5 x + 4
\]
$x^2 -5 x + 4 = 0$ voor $x_1, x_2$ met $x_{1,2} = \frac{5 \pm 3}{2}$ ($x_1 = 1$ en $x_2 = 4$)
\\
\[det(B) = \begin{vmatrix}
x & 0\\
5 & x + 2
\end{vmatrix}
 = x \cdot (x + 2) = x^2 + 2x\]
$x^2 + 2x$ voor $x_3, x_4$ met $x_3 = -2$ en $x_4 = 0$v 
\subsubsection*{Besluit}
$det(AB) = 0$ voor $x$ met $x \in \{-2, 0, 1, 4\}$.
\subsection{oef 4}
\subsubsection*{a)}
Aangezien er twee maal een ERO van het verwisselen van rijen voorkomt wordt de uitkomst:
$$-1\cdot -1\cdot -6 = -6$$
\subsubsection*{b)}
$$3\cdot(-1)\cdot 4 \cdot 6 = -72$$
\subsubsection*{c)}
\[ \text{De determinant blijft -6 (Stelling 2.3)} \]
\subsection*{oef 5}
Voor een $2\times2$ matrix, is deze determinant $-1$.
Voor elke grotere vierkante matrix is deze determinant $0$, omdat door rij reductie twee gelijke rijen kunnen gemaakt worden.
\[
\begin{vmatrix}
2 & 3 & 4\\
3 & 4 & 5\\
4 & 5 & 6
\end{vmatrix}
\overset{R2 \longmapsto R2-R1 \text{ en } R3 \longmapsto R3 - R1}{=}
\begin{vmatrix}
2 & 3 & 4\\
1 & 1 & 1\\
1 & 1 & 1
\end{vmatrix}
\]
\subsection{oef 6}
\subsubsection*{a)}
\[
det(A^{-1}) = \frac{1}{det(A)} $$
dus:
$$
det(A^{-1}) = \frac{1}{-7} 
\]
\subsubsection*{b)}
$$ det(2(A^{-1}) = 4\cdot det(A^{-1}) = 4 \cdot \frac{1}{-7} = \frac{-4}{7}
$$
\subsubsection*{c)}
\[ det((2A)^{-1}) = det(2A)^{-1} = 2^{3}det(A)^{-1} = -8/7\]
\subsection{oef 7}
\begin{proof}
De determinant van een product is het product van de determinanten.
\[
det(AB) = det(A) det(B) = 0 det(B) = 0 
\]
\end{proof}

\subsection{oef 8}
\begin{align*}
    \begin{vmatrix}
        k+2 & 1 & 1\\
        1 & k+2 & 1\\
        1 & 1 & k+2
    \end{vmatrix}
    &= (k+2) 
    \begin{vmatrix}
        k+2 & 1\\
        1 & k+2    
    \end{vmatrix} - 
    \begin{vmatrix}
        1 & 1\\
        1 & k+2
    \end{vmatrix} + 
    \begin{vmatrix}
        1 & 1\\
        k+2 & 1\\
    \end{vmatrix}\\
    &= (k+2)((k+2)^2 - 1) - (k+1) + (-k-1)\\
    &= (k+2)(k^2 + 4k + 3) -2k - 2\\
    &= k^3 + 6k^2 + 9k + 4
\end{align*}
De matrix is inverteerbaar als de determinant niet gelijk is aan 0.
\begin{align*}
    k^3 + 6k^2 + 9k + 4 &= (k+1)(k^2 + 5k + 4)\\
    &= (k+1)(k+1)(k+4)
\end{align*}
De matrix is dus inverteerbaar als $k \neq -1$ of $k \neq -4$.

\subsection{oef 9}
Basisgeval: \\
1) $(n=3, F_{3}=2):$
\[ 
\begin{pmatrix}
2 & 3\\ 
1 & 2
\end{pmatrix}
= 1 = (-1)^{3-1} = (-1)^{n-1}
\]
2) $(n=4, F_{4}=3:$
\[
\begin{pmatrix}
3 & 5\\ 
2 & 3
\end{pmatrix}
= -1 = (-1)^{4-1} = (-1)^{n-1}
\]
We kunnen van geval 1) naar geval 2) gaan door in geval 1) R2 $\longmapsto $ R2 + R1 en vervolgens R1 te verwisselen met R2. Deze eerste elementaire operatie veranderd niets aan de determinant, de tweede operatie veranderd slechts het teken. \\
\\
Algemeen:\\
Stel dat het klopt voor $F_{n-1}$\\
Te Bewijzen: het klopt voor $F_{n}$\\
Dit kunnen we doen door de uitleg die eerder gegeven werd.

\subsection{oef 11}
\subsubsection*{a)}
Waar: We kunnen de determinant van de matrix bepalen door er een bovendriehoeksmatrix van te maken en dan de elementen op de diagonaal te vermenigvuldigen. Dit kunnen we doen door zowel van A als D een bovendriehoeksmatrix te maken. Als we dit doen worden enkel de elementen van respectievelijk A en D aangepast (alle nullen blijven) dus de determinant is gelijk aan de det(A). det(B)

\subsubsection*{b)}
\begin{proof}
De matrices op de diagonaal van de samengestelde matrix: $A$ en $D$. kunnen we rijreduceren naar een echelonvorm zodat de elk diagonaal matrices worden ($A'$ en $D'$). Eventueel worden er dan bepaalde factoren voorop gezet ($a$ en $d$).
\[
\begin{vmatrix}
A & B\\
0 & D
\end{vmatrix}
=
ad
\begin{vmatrix}
A' & B\\
0 & D'
\end{vmatrix}
\]
Nu is het gemakkelijk te zien dat de volledige samengestelde matrix een diagonaalmatrix is.
Van een $n\times n$ diagonaalmatrix $X$ weten we het volgende.
\[
\det \left({X}\right) = \prod_{i \mathop = 1}^n x_{ii}
\]
Onze gezochte determinant is dan als volgt.
\[
ad
\begin{vmatrix}
A' & B\\
0 & D'
\end{vmatrix} = a\prod_{i \mathop = 1}^n a'_{ii} \cdot d \prod_{i \mathop = 1}^m d'_{ii} = \det \left({A}\right)\cdot\det \left({D}\right)
\]
\end{proof}

\subsubsection*{c)}
Niet waar, tegenvoorbeeld:
\begin{gather*}
    A = 
    \begin{pmatrix}
        1 & 2\\
        5 & 6
    \end{pmatrix} 
    , B = 
    \begin{pmatrix}
        3 & 4\\
        7 & 8
    \end{pmatrix}
    , C = 
    \begin{pmatrix}
        10 & 9\\
        13 & 14
    \end{pmatrix}
    , D = 
    \begin{pmatrix}
        11 & 12\\
        15 & 16
    \end{pmatrix}\\
    \begin{vmatrix}
        A & B\\
        C & D
    \end{vmatrix}
    = 0\\
    |A| \cdot |D| - |B| \cdot |C| = (-4) \cdot (-4) - (-4) \cdot 23 = 108
\end{gather*}


\subsection{oef 12}
\[
\begin{vmatrix}
2 & -1 & 3\\
-1 & 2 & 2\\
3 & 2 & 1
\end{vmatrix}
A_{11} : C_{11} = (-1)^(1+1) \cdot (2 - 4) = -2
A_{12} : C_{12} = (-1)^(1+2) \cdot (-1 -6) = 7
A_{13} : C_{13} = -8
A_{33} : C_{33} = 2
\]
\subsection{oef 13}
$$
\begin{vmatrix}
a & a^4 & a^7\\
a^2 & a^5 & a^8\\
a^3 & a^6 & a^9
\end{vmatrix}
\overset{R2 \longmapsto R2 - a \cdot R1}{=}
\begin{vmatrix}
a & a^4 & a^7\\
0 & 0 & 0\\
a^3 & a^6 & a^9
\end{vmatrix}
= 0
$$
Dit kan ook zo gedaan worden voor de derde rij. Vanaf dat ereen nulrij in zit weten we dat de determinant nul is.
\subsection{oef 14}
Voor elke scheefsymmetrische matrix geldt:
\[
A^T= -A
\]
\subsubsection*{Te bewijzen}
Voor $A\in R^{m\times n}$ met $n$ oneven.
\[
det(A) = 0
\]
\subsubsection*{Bewijs}
\[
A^T = -A
\]
\[
det(A^T) = det(-A)
\]
We weten:
\[
det(A^T) = det(A) \text{ en } det(-A) = (-1)^n det(A)
\]
dus
\[
det(A) = det(-A) \Rightarrow det(A) = 0
\]

\subsubsection*{tegenvoorbeeld}
\[
\begin{vmatrix}
0 & -1 & 0 & 0\\
1 & 0 & -1 & 0\\
0 & 1 & 0 & -1\\
0 & 0 & 1 & 0
\end{vmatrix}
\]
\subsection{oef 15}
\[ det(A-nI_{n})=0 \longmapsto \]
\[
\begin{pmatrix}
-(n-1) & 1 & 1 &... & 1\\
1 & -(n-1) & 1 & ... & 1\\
1 & 1 & -(n-1) & ... & 1\\
... & ... & ... & ... & ...\\
1 & 1 & 1 & ... & -(n-1)
\end{pmatrix} 
\]
\[R1 \leftrightarrow R_{N} \]
\[R2 \leftrightarrow R_{N-1} \]
\[...\]
\[
\begin{pmatrix}
1 & 1 & 1 & ... & -(n-1)\\
... & ... & ... & ... & ...\\
1 & 1 & -(n-1) & ... & 1\\
1 & -(n-1) & 1 & ... & 1\\
-(n-1) & 1 & 1 &... & 1
\end{pmatrix} 
\]
\[ \text{Als we deze matrix naar echelonvorm brengen zullen altijd een nulrij krijgen. Dus det=0}\]

\subsection{oef 16}
\subsubsection*{b)}
\[
\begin{vmatrix}
1 & 1 & 3\\
2 & 3 & 4\\
1 & 5 & 7
\end{vmatrix}
det(A) = 12
adj(A) =
\begin{vmatrix}
C_{11} & C_{21} & C_{31}\\
C_{21} & C_{22} & C_{32}\\
C_{13} & C_{23} & C_{33}
\end{vmatrix}
= 
\begin{vmatrix}
1 & -8 & -5\\
10 & 4 & -2\\
7 & 4 & 1
\end{vmatrix}
det(adj A) = 152
A^-1 = \frac{1}{det(A)} \cdot adj(A)
	 = \frac{1}{12} \cdot \begin{vmatrix}
	 						1 & -8	-5\\
	 						10 & 4 & -2\\
	 						7 & 4 & 1
	 					  \end{vmatrix}
\]


\subsection{oef 17}
\[
adj(A)=
\begin{pmatrix}
-3i & 4 & 10+16i\\
0 & 1+i & -5-4i\\
0 & 0 & 3+3i
\end{pmatrix}
\]

\subsection{oef 19}
\subsubsection*{19b)}
De uitleg staat tss "(())"
\[adj(A).A = det(A).I_{n}\]
\[adj(A.(adj(A))) = det(A)^{n-1}.I_{n}\]
\[((adj(A.B)=adj(A).adj(B)))\]
\[adj(A).adj(adj(A)) = det(A)^{n-1}.I_{n}\] 
\[(( \text{Beide kanten } \cdot A )) \]
\[(( adj(A).A = det(A).I_{n} )) \]
\[det(A).I_{n}.adj(adj(A)) = det(A)^{n-1}.A\]
\[((\text{We gaan er van uit dat de det(A) niet gelijk is aan nul }))\]
\[adj(adj(A)) = det(A)^{n-2}.A\]

\subsection{oef 20}
\subsubsection*{b)}
\[
WAAR.
adj(A) = CofactorenMatrix(A)^T (Def.)
dan is : (adj(A))^T = (CM(A)^T)^T
wat gewoon CM(A) oplevert.
vervolgens is : adj(A^T) = CM(A^T)^T
wat opnieuw CM(A) oplevert.
\]

\subsubsection*{oef 21}
\[A^{-1} = adj(A)/det(A)\]
\[adj(A) =
\begin{pmatrix}
3 & -5 & 2\\
0 & -1 & 1\\
-6 & 8 & -5
\end{pmatrix} 
\]
\[det(A)=-3\]

\subsubsection*{oef 23}
\[ A = 
\begin{pmatrix}
3 & -1 & 1\\
4 & 1 & 1\\
2 & -1 & 1
\end{pmatrix}
\]
\[ det(A) = 2\]
\[X1 = det 
\begin{pmatrix}
2 & -1 & 1\\
1 & 1 & 1\\
0 & -1 & 1
\end{pmatrix}
/2 = 4/2 = 2 \]
\[X2 = det
\begin{pmatrix}
3 & 2 & 1\\
4 & 1 & 1\\
2 & 0 & 1
\end{pmatrix}
/2 = -3/2 \]
\[X3 = det
\begin{pmatrix}
3 & -1 & 2\\
4 & 1 & 1\\
2 & -1 & 0
\end{pmatrix}
/2 = -11/2 \]

\subsection{oef 24}
\[ \left\{
     \begin{array}{lr}
       \frac{2}{x}-\frac{3}{y}+\frac{5}{z} = & 3 \\
       \frac{-4}{x}+\frac{7}{y}+\frac{2}{z} = & 0 \\
       \frac{2}{y}-\frac{1}{z} = & 2
     \end{array}
   \right. \Rightarrow\left\{
     \begin{array}{lr}
       2x'-3y'+5z' = & 3 \\
       -4x'+7y'+2z' = & 0 \\
       2y'-z' = & 2
     \end{array}
   \right.
\]
met $x' = \frac{1}{x}, y' = \frac{1}{y}, z' = \frac{1}{z}$

\[  d = \begin{vmatrix}
            2 & -3 & 5\\
            -4 & 7 & 2\\
            0 & 2 & -1
    \end{vmatrix} = -50,\]
\[  d_1 = \begin{vmatrix}
        3 & -3 & 5\\
        0 & 7 & 2\\
        2 & 2 & -1
    \end{vmatrix} = 73,\\
    d_2 = \begin{vmatrix}
        2 & 3 & 5\\
        -4 & 0 & 2\\
        0 & 2 & 1
    \end{vmatrix} = -36,\\
    d_3 = \begin{vmatrix}
        2 & -3 & 3\\
        -4 & 7 & 0\\
        0 & 2 & 2
    \end{vmatrix} = -20
\]

\[\Rightarrow x = (x')^{-1}= \frac{d}{d_1} = \frac{-50}{73},
    y = (y')^{-1}= \frac{d}{d_2} = \frac{50}{36},
    z = (z')^{-1}= \frac{d}{d_3} = \frac{50}{20}
\]

\subsection{oef 25}
De beschreven determinant ziet er als volgt uit.
\[
\begin{vmatrix}
1 & 0 & 0 & \cdots & 0 & x_1 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 & x_2 & 0 & \cdots & 0 \\
0 & 0 & 1 & \cdots & 0 & x_3 & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots  & \vdots & \vdots & \vdots &  & \vdots\\
0 & 0 & 0 & \cdots & 1 & x_{i-1} & 0 &\cdots & 0 \\
0 & 0 & 0 & \cdots & 0 & x_i & 0 & \cdots & 0 \\
0 & 0 & 0 & \cdots & 0 & x_{i+1} & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots &  & \vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \cdots & 0 & x_n & 0 & \cdots & 1\\
\end{vmatrix}
\]
Nu ontwikkelen we naar de eerste $i-1$ kolommen.
\[
= 
\begin{vmatrix}
x_i & 0 & \cdots & 0 \\
x_{i+1} & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots\\
 x_n & 0 & \cdots & 1\\
\end{vmatrix}
\]
Nu ontwikkelen we naar de laatste $n -i$ kolommen.
\[
= 
\begin{vmatrix}
x_i
\end{vmatrix}
= x_i
\]


\subsection{oef 27}
\subsubsection*{c)}
\[ \text{Niet waar, Stel c=2, n=3 en A=}
\begin{pmatrix}
3 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix} 
\]
\[c^{n}-det(A) = 8 - 3 = 5\]
\[ det (cI_{n}-A) = det
\begin{pmatrix}
-1 & 0 & 0 \\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}
= -1\]

\subsubsection*{d)}
\begin{proof}
\[
det(cI_n - A^T) = det(cI_n^T - A^T) = det(cI_n - A)
\]
\end{proof}

\subsubsection*{h)}
Niet waar. Tegenvoorbeeld: $A=I$ en $k=3$
\[
\rightarrow det(3A) = 27 \neq 3
\]
\subsubsection*{g}
 WAAR. ONVERBETERD(voorbereidende oefeningen maar ik was niet in de oefzitting aanwezig
eigschap van nilpotente matrix is dat zo'n matrix niet inverteerbaar is. We weten dat een inverteerbare matrix A gekenmerkt is door het feit dat zijn determinant verschillend van 0 is. Dus het feit dat 
nilpotenteMatrix niet inverteerbaar is betekent dat zijn determinant dus gelijk gaat zijn aan 0.
\subsubsection*{i)}
Niet waar. Tegenvoorbeeld: 
\[
    \begin{vmatrix}
        1 & 2 & 3\\
        4 & 5 & 6\\
        7 & 8 & 9
    \end{vmatrix} \neq
    \begin{vmatrix}
        5 & 3 & 8\\
        6 & 2 & 3\\
        7 & 8 & 9
    \end{vmatrix} + 
    \begin{vmatrix}
        -4 & -1 & -5\\
        -2 & 3 & 3\\
        7 & 8 & 9\\
    \end{vmatrix}
\]

\subsubsection*{n)}
niet waar:
\[
\begin{vmatrix}
1 & 0 & 1\\
1 & 1 & 0\\
0 & 1 & 1
\end{vmatrix}
=2
\]

\subsection*{extra}
Schrijf de volgende uitdrukking als een product van vier niet triviale factoren.
\[
\begin{vmatrix}
1+x & 1+x+x^{2} & 1+x+x^{2}+x^{3}\\
1+y & 1+y+y^{2} & 1+y+y^{2}+y^{3}\\
1+z & 1+z+z^{2} & 1+z+z^{2}+z^{3}
\end{vmatrix}
\]

\section{Opdrachten}
\subsection{2.14}
\subsection{2.16}
\subsubsection*{1.}
Permutaties van $\{1,2,3,4\}$:
$$
\{\{1, 2, 3, 4\}, \{1, 2, 4, 3\}, \{1, 3, 2, 4\}, \{1, 3, 4, 2\},$$
$$ \{1, 4, 2, 3\}, \{1, 4, 3, 2\}, \{2, 1, 3, 4\}, \{2, 1, 4, 3\}, $$ 
$$\{2, 3, 1, 4\}, \{2, 3, 4, 1\}, \{2, 4, 1, 3\}, \{2, 4, 3, 1\}, $$
$$\{3, 1, 2, 4\}, \{3, 1, 4, 2\}, \{3, 2, 1, 4\}, \{3, 2, 4, 1\}, $$ $$
\{3, 4, 1, 2\}, \{3, 4, 2, 1\}, \{4, 1, 2, 3\}, \{4, 1, 3, 2\}, $$
$$\{4, 2, 1, 3\}, \{4, 2, 3, 1\}, \{4, 3, 1, 2\}, \{4, 3, 2, 1\}\}
$$
Wat men eigenlijk doet voor een algemene matrix met deze permutaties is het volgende: begin met de standaard volgorde dit is: $\{1,2,3,4\}$.\\ Zet hieronder telkens een permutatie van deze volgorde, bijvoorbeeld:
$$\begin{pmatrix}
1 & 2 & 3 & 4\\
2 & 3 & 4 & 1
\end{pmatrix}
$$
Nu zijn de paarsgewijze koppels telkens de elementen uit de $4x4$ matrix die je moet nemen: $a_{12}$, $a_{23}$, $a_{34}$, $a_{41}$.\\
We kunnen nu ook nog het teken bepalen door te kijken naar het aan inversies:\\
$$1 < 2 \rightarrow 2 < 3$$
$$1 < 3 \rightarrow 3 < 4$$
$$1 < 4 \rightarrow 2 > 1 \ inversie$$
$$2 < 3 \rightarrow 3 < 4$$
$$2 < 4 \rightarrow 3 > 1 \ inversie$$
$$3 < 4 \rightarrow 4 > 1 \ inversie$$
Er zijn dus in totaal 3 inversies, het teken van de permutatie is dus negatief:
$$-a_{12}\cdot a_{23}\cdot a_{34}\cdot a_{41}$$
\subsubsection*{2.}
Op een algemene matrix:
$$
\begin{pmatrix}
a & b & c & d\\
e & f & g & h\\
i & j & k & l\\
m & n & o & p
\end{pmatrix}
$$
zou dit dan zijn:
$$-b\cdot g\cdot l\cdot m$$
Voor de uiteindelijke determinant moeten we deze stappen dus herhalen voor al de permutaties.
\end{document}
